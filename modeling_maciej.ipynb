{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From start to json/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import *\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "#for many json texts\n",
    "import glob\n",
    "\n",
    "#visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"mongodb://bouman:80um4N!@ec2-15-188-255-64.eu-west-3.compute.amazonaws.com:27017/\"\n",
    "client = MongoClient(connection)\n",
    "db = client.get_database ('media_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = db[\"articles\"]\n",
    "#IT WORKS LEZGO\n",
    "fr_news = col.find({'meta.source.language': 'fr'},{\"_id\":0,\"title\": 1,\"text\":1,\"date\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"one_article_i_guess_final.csv\", 'w', encoding='UTF-8', newline='') as file:\n",
    "  writer = csv.writer(file)\n",
    "  for article in fr_news:  \n",
    "    writer.writerow([article[\"text\"]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Assuming fr_news is a list of dictionaries with \"text\", \"title\", and \"author\" keys.\n",
    "\n",
    "def process_article(article):\n",
    "    return [article[\"title\"],article[\"text\"]]\n",
    "\n",
    "with open(\"fr_with_threads.csv\", 'a', encoding='UTF-8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Choose the number of threads in the ThreadPoolExecutor (e.g., 4 in this case).\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Process each article using the thread pool and write the results to the CSV file.\n",
    "        for row in executor.map(process_article, fr_news):\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IT STOPS AFTER APPROX 25 SEC\n",
    "import csv\n",
    "\n",
    "with open(\"all_french.csv\", 'w', encoding='UTF-8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "   \n",
    "    for article in fr_news:\n",
    "        \n",
    "        row = [article[\"title\"],article[\"text\"]]\n",
    "        writer.writerow(row)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in fr_news:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"one_article3.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  for article in col:  \n",
    "    writer.writerow(col)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_news.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col[article].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.stop('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN IT\n",
    "for x in fr_news:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for article in fr_news:\n",
    "    print(article.title)\n",
    "    #print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test topic modeling on one article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "only_french = col.\n",
    "with open(\"one_article2.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  for article in only_french:\n",
    "    writer.writerow(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "#dunno how it works tbh\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('fr_3k.csv')\n",
    "documents = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample = documents\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just retrieving some data for practicing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = db[\"articles\"]\n",
    "#IT WORKS LEZGO\n",
    "#Seems like the max at once is 3 000 elements\n",
    "fr_news = col.find({'meta.source.language': 'fr'},{\"_id\":0,\"title\": 1,\"text\":1,\"date\":1}).limit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "fields = [\"title\",\"text\",\"date\"]\n",
    "with open(\"fr_3k_to_csv.csv\", 'w', encoding='UTF-8', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fields)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for article in fr_news:\n",
    "        \n",
    "        row = [article[\"title\"],article[\"text\"]]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to transform into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I really don't know what I'm doing\n",
    "import pandas as pd\n",
    "df_idf = pd.read_json(\"fr_texts.json\",lines=True)\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of questions,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"\",\"\",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#df_idf['text'] = df_idf['title'] + df_idf['body']\n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "#show the second 'text' just for fun\n",
    "df_idf['text'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating vocabulary and word counts for idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "#we don't load.\n",
    "stopwords=stopwords(\"only_french\")\n",
    "\n",
    "#get the text column \n",
    "docs=df_idf['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from start to dataframes\n",
    "inspiration : https://curiousml.github.io/teaching/DSA/dsa_nlp_tp_corr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import *\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "#for many json texts\n",
    "import glob\n",
    "\n",
    "#visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"mongodb://bouman:80um4N!@ec2-15-188-255-64.eu-west-3.compute.amazonaws.com:27017/\"\n",
    "client = MongoClient(connection)\n",
    "db = client.get_database ('media_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = db[\"articles\"]\n",
    "#IT WORKS LEZGO\n",
    "fr_news = col.find({'meta.source.language': 'fr'},{\"_id\":0,\"title\": 1,\"text\":1,\"date\":1}).limit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=fr_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of 5 000 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking how many null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting rows with null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fr_sample_10k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(texts))\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spacy_docs = list(nlp.pipe(texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "docs = []\n",
    "for doc in spacy_docs:\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if len(token.orth_) > 3 and not token.is_stop: # prétraitements 1 et 2\n",
    "            tokens.append( token.lemma_.lower() )  # prétraitements 3 et 4\n",
    "    docs.append( tokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models import Phrases\n",
    "\n",
    "bigram = Phrases(docs, min_count=10)\n",
    "\n",
    "for index in range(len(docs)):\n",
    "    for token in bigram[docs[index]]:\n",
    "        if '_' in token: \n",
    "            docs[index].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams & trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(docs, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[docs], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[docs[2]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I really have no idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(docs)\n",
    "#dictionary = Dictionary(data_bigrams_trigrams)\n",
    "print('unique terms initially :', len(dictionary))\n",
    "\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.25)\n",
    "print('unique terms after modification :', len(dictionary))\n",
    "\n",
    "print(\"test :\", dictionary.doc2bow(docs[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, chunksize=1000, passes=5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (topic, words) in model.print_topics():\n",
    "    print(\"***********\")\n",
    "    print(\"* topic\", topic+1, \"*\")\n",
    "    print(\"***********\")\n",
    "    print(topic+1, \":\", words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import warnings\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "pyLDAvis.gensim_models.prepare(model, corpus, dictionary, sort_topics=False, R=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_doc = 4\n",
    "i = 0\n",
    "for (text, doc) in zip(texts[:n_doc], docs[:n_doc]):\n",
    "    i += 1\n",
    "    print(\"***********\")\n",
    "    print(\"* article \", i, \"  *\")\n",
    "    print(\"***********\")\n",
    "    print(text)\n",
    "    print([(topic+1, prob) for (topic, prob) in model[dictionary.doc2bow(doc)] if prob > 0.1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  assessing coherenece metric of the model\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "topics = [['etats-unis', 'pays', 'endeuiller', 'épidémie', 'coronavirus', 'enregistrer', '1255', 'décès', 'supplémentaire', 'lier', 'covid-19', 'dernier', 'heure', 'comptage', 'continu', 'université', 'john', 'hopkins', 'référence', 'jeudi', 'soir', 'total', '94.661', 'personne', 'officiellement', 'mourir', 'cause', 'coronavirus', 'pays', '1.576.542', 'diagnostiquer', '25.582', 'supplémentaire', '20h30', 'mercredi', 'jeudi', 'soir', 'raison', 'difficulté', 'accès', 'test', 'grand', 'public', 'véritable', 'nombre', 'infection', 'probablement', 'bien', 'supérieur', 'lire', 'pékin', 'réfuter', 'propos', 'trump', 'accuser', 'chine', 'tuerie', 'masse', 'ajouter', 'nombre', 'mort', 'canada', 'bien', 'sévèrement', 'toucher', 'voisin', 'amérique', 'nord', 'venir', 'franchir', 'barrière', '100.000', 'mort', 'devoir', 'bientôt', 'passer', 'etats-unis', 'prévision', 'pression', 'opposition', 'président', 'donald', 'trump', 'indiquer', 'drapeau', 'berne', 'bâtiment', 'fédéral', 'monument', 'national', 'vendredi', 'dimanche', 'chiffre', 'officiel', 'etats-unis', 'million', 'habitant', 'pays', 'endeuiller', 'pandémie', 'valeur', 'absolu', 'pays_endeuiller', 'épidémie_coronavirus', 'décès_supplémentaire', 'lier_covid-19', 'dernier_heure', 'université_john', 'jeudi_soir', 'cause_coronavirus', 'jeudi_soir', 'trump_accuser', 'tuerie_masse', 'nombre_mort', 'président_donald', 'chiffre_officiel', 'million_habitant', 'pays_endeuiller']]\n",
    "\n",
    "# Coherence model\n",
    "cm = CoherenceModel(topics=topics, \n",
    "                    texts=corpus,\n",
    "                    coherence='c_v',  \n",
    "                    dictionary=dictionary)\n",
    "\n",
    "coherence_per_topic = cm.get_coherence_per_topic()\n",
    "coherence_per_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3 another approach, dataframes with a guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from pymongo import *\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "#for many json texts\n",
    "import glob\n",
    "\n",
    "#visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection\n",
    "connection = \"mongodb://bouman:80um4N!@ec2-15-188-255-64.eu-west-3.compute.amazonaws.com:27017/\"\n",
    "client = MongoClient(connection)\n",
    "db = client.get_database ('media_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all articles\n",
    "col = db[\"articles\"]\n",
    "#IT WORKS LEZGO\n",
    "fr_news = col.find({'meta.source.language': 'fr'},{\"_id\":0,\"title\": 1,\"text\":1,\"date\":1}).limit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Into the DataFrame\n",
    "df = pd.DataFrame(data=fr_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     0\n",
       "text     0\n",
       "title    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking how many null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting rows with null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Jamal Khashoggi, critique du régime saoudien a...\n",
       "1    Coronavirus: plus de 1.200 nouveaux morts aux ...\n",
       "2    Les concentrations de différents polluants rel...\n",
       "3    Vous avez aimé la bataille hivernale entre les...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[\"text\"]\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT RUN\n",
    "# def lemmatization(texts,allowed_postags=[\"NOUN\",\"ADJ\",\"VERB\",\"ADV\"]):\n",
    "#     nlp = spacy.load(\"fr_core_news_sm\",disable=[\"parser\",\"ner\"])\n",
    "#     texts_out = []\n",
    "#     for text in texts:\n",
    "#         doc = nlp(text)\n",
    "#         new_text = []\n",
    "#         for token in doc:\n",
    "#             if token.pos_ in allowed_postags:\n",
    "#                 new_text.append(token.lemma_)\n",
    "#                 final = \" \".join(new_text)\n",
    "#                 texts_out.append(final)\n",
    "#     return (texts_out)\n",
    "\n",
    "# lemmatized_texts = lemmatization(data)\n",
    "# print(lemmatized_texts[:90])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jamal Khashoggi critique régime saoudien après avoir proche a assassiné corps découpé morceaux octobre Les enfants Jamal Khashoggi journaliste saoudien assassiné octobre consulat d’Arabie saoudite Istanbul annoncé vendredi qu’ils pardonnaient tueurs père « Nous fils martyr Jamal Khashoggi annonçons pardonnons ceux tué père » a écrit Twitter Salah Khashoggi fils l’ancien journaliste Washington Post Un meurtre odieux Jamal Khashoggi critique régime saoudien après avoir proche a assassiné corps découpé morceaux octobre consulat d’Arabie saoudite Istanbul où s’était rendu récupérer document'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import re\n",
    "\n",
    "data_synonyms = [\n",
    "    \"donnée\",\n",
    "    \"information\",\n",
    "    \"ensemble de données\",\n",
    "    \"jeu de données\",\n",
    "    \"base de données\",\n",
    "    \"informations\",\n",
    "    \"enregistrement\",\n",
    "    \"document\",\n",
    "    \"fait\",\n",
    "    \"renseignement\"\n",
    "]\n",
    "def remove_stops(text, stops):\n",
    "    words = text.split()\n",
    "    final = []\n",
    "    for word in words:\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "    final = \" \".join(final)\n",
    "    final = final.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    final = \"\".join([i for i in final if not i.isdigit()])\n",
    "    while \"  \"in final:\n",
    "        final = final.replace(\"  \",\" \")\n",
    "    return (final)\n",
    "    \n",
    "def clean_docs(docs):\n",
    "    stops = stopwords.words(\"french\")\n",
    "    #stops = stops + data_synonyms\n",
    "    final = []\n",
    "    for doc in docs:\n",
    "        clean_doc = remove_stops(doc,stops)\n",
    "        final.append(clean_doc)\n",
    "    return (final)\n",
    "\n",
    "data = clean_docs(data)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_docs = list(nlp.pipe(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for doc in spacy_docs:\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if len(token.orth_) > 3 and not token.is_stop: # prétraitements 1 et 2\n",
    "            tokens.append( token.lemma_.lower() )  # prétraitements 3 et 4\n",
    "    docs.append( tokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jamal', 'khashoggi', 'critique', 'régime', 'saoudien', 'assassiner', 'corps', 'découper', 'morceal', 'octobre', 'enfant', 'jamal', 'khashoggi', 'journaliste', 'saoudien', 'assassiné', 'octobre', 'consulat', 'arabie', 'saoudite', 'istanbul', 'annoncer', 'vendredi', 'pardonner', 'tueur', 'pèr', 'fils', 'martyr', 'jamal', 'khashoggi', 'annonçon', 'pardonnon', 'père', 'écrire', 'twitter', 'salah', 'khashoggi', 'fils', 'ancien', 'journaliste', 'washington', 'post', 'meurtre', 'odieux', 'jamal', 'khashoggi', 'critique', 'régime', 'saoudien', 'assassiner', 'corps', 'découper', 'morceal', 'octobre', 'consulat', 'arabie', 'saoudite', 'istanbul', 'rendre', 'récupérer', 'document']\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jamal_khashoggi', 'critique', 'régime', 'saoudien', 'assassiner', 'corps', 'découper', 'morceal', 'octobre', 'enfant', 'jamal_khashoggi', 'journaliste', 'saoudien', 'assassiné', 'octobre_consulat', 'arabie_saoudite', 'istanbul', 'annoncer', 'vendredi', 'pardonner', 'tueur', 'pèr', 'fils', 'martyr', 'jamal_khashoggi', 'annonçon', 'pardonnon', 'père', 'écrire', 'twitter', 'salah_khashoggi', 'fils', 'ancien', 'journaliste', 'washington_post', 'meurtre', 'odieux', 'jamal_khashoggi', 'critique', 'régime', 'saoudien', 'assassiner', 'corps', 'découper', 'morceal', 'octobre_consulat', 'arabie_saoudite', 'istanbul', 'rendre', 'récupérer', 'document']\n"
     ]
    }
   ],
   "source": [
    "#Seems OK\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(docs, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[docs], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[docs[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopwords] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['critique', 'régime', 'saoudien', 'assassiner', 'corps', 'découper', 'morceal', 'octobre', 'journalist', 'saoudien', 'assassiné', 'istanbul', 'annoncer', 'vendredi', 'pardonner', 'tueur', 'fils', 'martyr', 'annonçon', 'pardonnon', 'pèr', 'écrir', 'twitter', 'salah_khashoggi', 'fils', 'ancien', 'journaliste', 'washington_post', 'meurtr', 'odieux', 'critique', 'régime', 'saoudien', 'assassiner', 'corps', 'découper', 'morceal', 'arabie_saoudite', 'istanbul', 'rendre', 'récupérer', 'document'], ['coronavirus', 'nouveau', 'mort', 'étatsunis', 'trump', 'drapeal', 'américain', 'honorer', 'victime', 'donald_trump', 'annoncer', 'jeudi', 'mettre', 'jour', 'drapeal', 'flottant', 'édifice', 'fédéral', 'américain', 'honorer', 'mémoir', 'victime', 'coronavirus', 'mettre', 'bern', 'drapeal', 'bâtiment', 'fédéral', 'monument', 'national', 'prochain', 'jour', 'mémoir', 'américain', 'perdre', 'cause', 'coronavirus', 'tweeter', 'président', 'américain', 'décès', 'supplémentaire', 'etatsuni', 'pays', 'endeuiller', 'épidémie', 'coronavirus', 'enregistrer', 'décè_supplémentaire', 'lier', 'covid', 'dernier', 'heure', 'comptage', 'continu', 'hopkins_référence', 'jeudi', 'soir'], ['concentration', 'polluant', 'relever', 'mars', 'comparer', 'donner', 'amélioration', 'qualité', 'bruxellois', 'terme', 'mois', 'demi', 'confinemer', 'traduire', 'bais', 'concentration', 'monoxyde', 'azote', 'aller', '’', 'site', 'habituellement', 'fortement_exposer', 'émission', 'trafic', 'automobile', 'rapport', 'bruxelle', 'environnement', 'présenter', 'vendredi', 'cabinet_ministre', 'régional', 'concentration', 'polluant', 'relever', 'mars', 'comparer', 'donner', 'diminution', 'important', 'station', 'fortement_exposer', 'trafic', 'monoxyde', 'azote', 'localiser', 'source', 'émission', 'diminuer', 'dioxyde', 'carbon', 'station', 'exposer', 'concentration', 'baisser']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "#data_words_nostops = remove_stopwords(docs)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(docs)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('fr_core_news_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:3])\n",
    "#Seems like it cuts weirdly, it has \"pèr\" and \"père\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 2), (7, 2), (8, 1), (9, 2), (10, 2), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 3), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "#replace docs by data_lemmatized\n",
    "#id2word = corpora.Dictionary(docs)\n",
    "\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "#replace docs by data_lemmatized\n",
    "#texts = docs\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assassiné'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=12, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=400,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.031*\"octobre\" + 0.027*\"septembr\" + 0.024*\"témoin\" + 0.020*\"philipp\" + '\n",
      "  '0.020*\"Monsieur\" + 0.017*\"regretter\" + 0.015*\"campagne\" + 0.015*\"maître\" + '\n",
      "  '0.015*\"tribunal_correctionnel\" + 0.014*\"peine\"'),\n",
      " (1,\n",
      "  '0.044*\"corps\" + 0.040*\"salle\" + 0.026*\"muser\" + 0.025*\"sciensano\" + '\n",
      "  '0.021*\"attaquer\" + 0.017*\"prince\" + 0.016*\"note\" + 0.016*\"concert\" + '\n",
      "  '0.015*\"musicien\" + 0.015*\"carte\"'),\n",
      " (2,\n",
      "  '0.043*\"client\" + 0.029*\"respecter\" + 0.028*\"magasin\" + 0.026*\"sécurité\" + '\n",
      "  '0.024*\"visiteur\" + 0.023*\"véhicule\" + 0.017*\"voitur\" + 0.017*\"maximum\" + '\n",
      "  '0.016*\"lieux\" + 0.015*\"limité\"'),\n",
      " (3,\n",
      "  '0.013*\"mesure\" + 0.012*\"pouvoir\" + 0.010*\"permettre\" + 0.010*\"gouvernement\" '\n",
      "  '+ 0.010*\"covid\" + 0.009*\"coronavirus\" + 0.009*\"public\" + 0.009*\"pandémie\" + '\n",
      "  '0.008*\"pays\" + 0.008*\"million\"'),\n",
      " (4,\n",
      "  '0.120*\"police\" + 0.053*\"policier\" + 0.034*\"parquet\" + 0.033*\"propriétaire\" '\n",
      "  '+ 0.026*\"facebook\" + 0.019*\"amateur\" + 0.019*\"organisateur\" + '\n",
      "  '0.012*\"cycliste\" + 0.011*\"coureur\" + 0.011*\"tour_france\"'),\n",
      " (5,\n",
      "  '0.053*\"euro\" + 0.042*\"crise\" + 0.030*\"entreprise\" + 0.026*\"secteur\" + '\n",
      "  '0.022*\"marché\" + 0.018*\"économique\" + 0.017*\"perte\" + 0.016*\"entreprendre\" '\n",
      "  '+ 0.015*\"européen\" + 0.015*\"veille\"'),\n",
      " (6,\n",
      "  '0.104*\"enfant\" + 0.070*\"école\" + 0.034*\"élever\" + 0.031*\"parer\" + '\n",
      "  '0.026*\"expert\" + 0.020*\"rentrer\" + 0.016*\"technologie\" + 0.016*\"prison\" + '\n",
      "  '0.016*\"classe\" + 0.015*\"application\"'),\n",
      " (7,\n",
      "  '0.017*\"américain\" + 0.012*\"président\" + 0.012*\"jamais\" + 0.010*\"chose\" + '\n",
      "  '0.009*\"femme\" + 0.009*\"histoire\" + 0.009*\"licence\" + 0.008*\"dautr\" + '\n",
      "  '0.008*\"monde\" + 0.008*\"français\"'),\n",
      " (8,\n",
      "  '0.035*\"belga\" + 0.029*\"journée\" + 0.021*\"conducteur\" + 0.021*\"culture\" + '\n",
      "  '0.019*\"marque\" + 0.017*\"princesse\" + 0.014*\"comédien\" + 0.014*\"royal\" + '\n",
      "  '0.014*\"papa\" + 0.013*\"chauffeur\"'),\n",
      " (9,\n",
      "  '0.034*\"acteur\" + 0.027*\"proposition\" + 0.023*\"futur\" + 0.022*\"allemand\" + '\n",
      "  '0.018*\"sujet\" + 0.017*\"artiste\" + 0.017*\"film\" + 0.016*\"collectif\" + '\n",
      "  '0.015*\"plateform\" + 0.014*\"ménage\"'),\n",
      " (10,\n",
      "  '0.029*\"ligue_champion\" + 0.015*\"concours\" + 0.014*\"ballon\" + '\n",
      "  '0.012*\"concour\" + 0.007*\"correctement\" + 0.007*\"entériner\" + '\n",
      "  '0.007*\"interprèt\" + 0.006*\"minuit\" + 0.006*\"approcher\" + 0.006*\"suède\"'),\n",
      " (11,\n",
      "  '0.012*\"dernier\" + 0.011*\"bien\" + 0.010*\"jour\" + 0.009*\"prendre\" + '\n",
      "  '0.009*\"grand\" + 0.008*\"faire\" + 0.008*\"devoir\" + 0.007*\"passer\" + '\n",
      "  '0.007*\"mois\" + 0.007*\"nouveau\"'),\n",
      " (12,\n",
      "  '0.079*\"club\" + 0.077*\"saison\" + 0.048*\"joueur\" + 0.035*\"championnat\" + '\n",
      "  '0.029*\"football\" + 0.025*\"équipe\" + 0.024*\"sportif\" + 0.024*\"match\" + '\n",
      "  '0.023*\"jouer\" + 0.022*\"reprendre\"'),\n",
      " (13,\n",
      "  '0.016*\"vert\" + 0.013*\"bleu\" + 0.012*\"pur\" + 0.012*\"commettr\" + '\n",
      "  '0.011*\"blessure\" + 0.011*\"inacceptable\" + 0.011*\"jusquelà\" + '\n",
      "  '0.010*\"agression\" + 0.010*\"coulisse\" + 0.007*\"président_georgesloui\"'),\n",
      " (14,\n",
      "  '0.027*\"parc\" + 0.022*\"matière\" + 0.020*\"animal\" + 0.020*\"procédure\" + '\n",
      "  '0.018*\"charleroi\" + 0.018*\"évoluer\" + 0.017*\"cour\" + 0.016*\"mouscron\" + '\n",
      "  '0.015*\"frontièr\" + 0.015*\"tirer\"'),\n",
      " (15,\n",
      "  '0.042*\"virton\" + 0.034*\"heur\" + 0.016*\"précis\" + 0.014*\"seuil\" + '\n",
      "  '0.013*\"boi\" + 0.012*\"téléphonique\" + 0.012*\"julien\" + 0.010*\"poudre\" + '\n",
      "  '0.010*\"justement\" + 0.009*\"leagu\"'),\n",
      " (16,\n",
      "  '0.028*\"peur\" + 0.026*\"circuit\" + 0.026*\"émission\" + 0.025*\"équiper\" + '\n",
      "  '0.025*\"moto\" + 0.024*\"célèbre\" + 0.023*\"instagram\" + 0.019*\"efficace\" + '\n",
      "  '0.017*\"soleil\" + 0.013*\"plaindre\"'),\n",
      " (17,\n",
      "  '0.039*\"article\" + 0.031*\"jusquà\" + 0.028*\"formul\" + 0.027*\"déterminer\" + '\n",
      "  '0.026*\"expérience\" + 0.024*\"hospitaliser\" + 0.023*\"vendre\" + 0.016*\"gand\" + '\n",
      "  '0.016*\"eric\" + 0.015*\"racheter\"'),\n",
      " (18,\n",
      "  '0.039*\"nombre\" + 0.035*\"patient\" + 0.033*\"covid\" + 0.033*\"hôpital\" + '\n",
      "  '0.032*\"mort\" + 0.032*\"avril\" + 0.028*\"coronavirus\" + 0.027*\"virus\" + '\n",
      "  '0.026*\"test\" + 0.023*\"maladie\"'),\n",
      " (19,\n",
      "  '0.035*\"région\" + 0.027*\"commun\" + 0.023*\"zone\" + 0.020*\"bruxelle\" + '\n",
      "  '0.018*\"ville\" + 0.017*\"bruxellois\" + 0.016*\"communal\" + 0.015*\"local\" + '\n",
      "  '0.015*\"voiture\" + 0.013*\"commercer\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -10.286451567342397\n",
      "\n",
      "Coherence Score:  0.4774617689889184\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "#replace docs by data_lemmatized\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "#Best coherence = 0.49 (10 topics, 500 chunk_size)\n",
    "#nice graph coh 0.45 (13 200)\n",
    "#0.48 (13 400)\n",
    "#0.49 (12 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el36425421888143845833867562\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el36425421888143845833867562_data = {\"mdsDat\": {\"x\": [0.16911879199558155, 0.16415601029940197, 0.1445804879645622, 0.10685309208924704, 0.0667425017866165, 0.11430214946813634, 0.020563459350151757, -0.005560728740312398, 0.06346707611037061, -0.28971508077117747, -0.2789726793428527, -0.2755350802097257], \"y\": [-0.03705404854184922, -0.004438601695758004, 0.14167790649312353, -0.12956880034730808, -0.08685134287251944, 0.06538253906972895, -0.12203773120850248, -0.1250282508569751, 0.2446455399277679, 0.019885222900823528, 0.021158979990953862, 0.012228587140514518], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [17.32285829853918, 16.802366191758715, 14.196478232640313, 10.413538389818942, 10.18969750369104, 10.16785641197872, 6.924044127362067, 6.334178807016731, 5.876672226563986, 0.9579510564444877, 0.6085551790464615, 0.20580357513935782]}, \"tinfo\": {\"Term\": [\"saison\", \"club\", \"covid\", \"crise\", \"police\", \"joueur\", \"am\\u00e9ricain\", \"pr\\u00e9sident\", \"\\u00e9cole\", \"reprendre\", \"coronavirus\", \"nombre\", \"euro\", \"enfant\", \"championnat\", \"virus\", \"sant\\u00e9\", \"trouver\", \"homme\", \"avril\", \"\\u00e9quipe\", \"patient\", \"jeune\", \"ministre\", \"masqu\", \"prochain\", \"h\\u00f4pital\", \"football\", \"lundi\", \"ao\\u00fbt\", \"magasin\", \"entreprendre\", \"montant\", \"employer\", \"vente\", \"salair\", \"euro\", \"milliard\", \"croissance\", \"li\\u00e9geois\", \"abonner\", \"entreprise_familial\", \"trimestre\", \"argent\", \"actionnair\", \"chute\", \"baisse\", \"banqu\", \"opportunit\\u00e9\", \"r\\u00e9duction\", \"union\", \"coll\\u00e8ge\", \"relance\", \"sp\\u00e9cialiser\", \"hydroalcoolique\", \"lactivit\\u00e9\", \"d\\u00e9pense\", \"horeca\", \"touristique\", \"effectif\", \"perte\", \"marque\", \"co\\u00fbt\", \"march\\u00e9\", \"crise\", \"visiteur\", \"financier\", \"\\u00e9conomie\", \"entreprise\", \"m\\u00e9nage\", \"million\", \"secteur\", \"occasion\", \"\\u00e9conomique\", \"repr\\u00e9senter\", \"payer\", \"marcher\", \"point\", \"aide\", \"impact\", \"emploi\", \"activit\\u00e9\", \"ann\\u00e9e\", \"soci\\u00e9t\\u00e9\", \"mois\", \"mesure\", \"part\", \"important\", \"plan\", \"gouvernement\", \"grand\", \"rapport\", \"groupe\", \"permettre\", \"belge\", \"dernier\", \"service\", \"devoir\", \"travail\", \"avril\", \"coronavirus\", \"parc\", \"cookie\", \"plage\", \"animal\", \"pairi_daiza\", \"frais\", \"jeu\", \"financer\", \"biodiversit\\u00e9\", \"utilisation\", \"vendr\", \"gratuit\", \"tokyo\", \"mobiliser\", \"jardin\", \"commander\", \"r\\u00e9servation\", \"esp\\u00e8ce\", \"climat\", \"alternatif\", \"limiter\", \"olympique\", \"v\\u00e9lo\", \"environnemental\", \"manger\", \"fournisseur\", \"parfaitement\", \"voyager\", \"loccasion\", \"discovery\", \"nature\", \"transport\", \"client\", \"utiliser\", \"command\", \"vaccin\", \"mobilit\\u00e9\", \"citoyen\", \"strat\\u00e9gie\", \"large\", \"technologie\", \"exister\", \"disponible\", \"r\\u00e9gion\", \"produire\", \"prot\\u00e9ger\", \"protection\", \"pratique\", \"application\", \"syst\\u00e8me\", \"ville\", \"permettre\", \"public\", \"pouvoir\", \"lancer\", \"europ\\u00e9en\", \"nouveau\", \"groupe\", \"donner\", \"s\\u00e9curit\\u00e9\", \"commun\", \"falloir\", \"bon\", \"place\", \"bien\", \"devoir\", \"sant\\u00e9\", \"prendre\", \"mesure\", \"ministre\", \"concerner\", \"belgiqu\", \"belge\", \"compagnie\", \"article\", \"film\", \"artiste\", \"tournage\", \"r\\u00e9alisateur\", \"compagnie_a\\u00e9rien\", \"chanteur\", \"beau\", \"regarder\", \"instagram\", \"spectacle\", \"demain\", \"princesse\", \"royal\", \"couple\", \"parking\", \"compte_acc\\u00e8\", \"business\", \"acc\\u00e8s_contenu\", \"compte_lire\", \"voulezvou_changer\", \"anniversaire\", \"m\\u00e8r\", \"cin\\u00e9ma\", \"a\\u00e9roport\", \"coupl\", \"th\\u00e9\\u00e2tre\", \"charle\", \"homm\", \"port\", \"histoire\", \"acteur\", \"\\u00e9dition\", \"fille\", \"sc\\u00e8ne\", \"trouver\", \"sauver\", \"chose\", \"changer\", \"voir\", \"propri\\u00e9taire\", \"gar\\u00e7on\", \"sortie\", \"bien\", \"vraiment\", \"vivre\", \"vouloir\", \"\\u00e9crir\", \"beaucoup\", \"temps\", \"confier\", \"moment\", \"grand\", \"passer\", \"\\u2019\", \"savoir\", \"sortir\", \"jour\", \"prendre\", \"confinemer\", \"expliquer\", \"jamais\", \"aller\", \"faire\", \"petit\", \"pouvoir\", \"nouveau\", \"venir\", \"ann\\u00e9e\", \"devoir\", \"mettre\", \"belge\", \"patient\", \"maladie\", \"chiffr\", \"contaminer\", \"malade\", \"contamination\", \"infection\", \"recenser\", \"infecter\", \"hospitaliser\", \"sciensano\", \"unit\\u00e9\", \"hospitalisation\", \"soin_intensif\", \"clinique\", \"sympt\\u00f4me\", \"d\\u00e9tecter\", \"caf\\u00e9\", \"chauffeur\", \"hospitalier\", \"jordan\", \"tester_positif\", \"contrairement\", \"sarscov\", \"stib\", \"virologue\", \"mensuel\", \"contagion\", \"m\\u00e9decine\", \"mexiqu\", \"virus\", \"m\\u00e9decin\", \"viru\", \"h\\u00f4pital\", \"d\\u00e9c\\u00e8s\", \"m\\u00e9dicament\", \"test\", \"covid\", \"\\u00e9pid\\u00e9mie\", \"enregistrer\", \"nombre\", \"vague\", \"mort\", \"d\\u00e9c\\u00e8\", \"sant\\u00e9\", \"veille\", \"avril\", \"coronavirus\", \"total\", \"personne\", \"jour\", \"chiffre\", \"nouveau\", \"dernier\", \"risque\", \"d\\u00e9but\", \"\\u00e9tude\", \"mars\", \"personn\", \"pays\", \"rapport\", \"belgiqu\", \"heure\", \"mesure\", \"donald_trump\", \"chinois\", \"assembl\\u00e9e_g\\u00e9n\\u00e9ral\", \"russie\", \"lafp\", \"magazine\", \"trump\", \"lancien\", \"hong_kong\", \"sommet\", \"visioconf\\u00e9rence\", \"\\u00e9tatsuni\", \"d\\u00e9g\\u00e2t\", \"gardien\", \"journaliste\", \"audience\", \"quun\", \"rang\", \"proc\\u00e8s\", \"ferrari\", \"lib\\u00e9rer\", \"p\\u00e9kin\", \"alonso\", \"lhistoir\", \"final_coupe\", \"r\\u00e9gime\", \"l\\u00eele\", \"artificiel\", \"rejeter\", \"mercede\", \"am\\u00e9ricain\", \"chin\", \"etatsuni\", \"renault\", \"d\\u00e9put\\u00e9\", \"pr\\u00e9sident\", \"traiter\", \"britannique\", \"qualifier\", \"s\\u00e9ter\", \"dirigeant\", \"quil\", \"atil\", \"d\\u00e9fense\", \"accuser\", \"presse\", \"affirmer\", \"candidat\", \"sest\", \"d\\u00e9clarer\", \"mondial\", \"pays\", \"ancien\", \"patron\", \"relation\", \"responsable\", \"m\\u00e9dia\", \"annoncer\", \"chef\", \"dernier\", \"politique\", \"pand\\u00e9mie\", \"national\", \"pay\", \"grand\", \"coronavirus\", \"jeudi\", \"vendredi\", \"d\\u00e9but\", \"international\", \"\\u00e9cole\", \"parer\", \"visite\", \"muser\", \"v\\u00e9hicul\", \"bo\\u00eete\", \"scolaire\", \"namur\", \"enseigner\", \"exposition\", \"hainaut\", \"\\u00e9chevin\", \"amuser\", \"masqu\", \"enseignemer\", \"avenue\", \"espac\", \"enseignement\", \"emmener\", \"imm\\u00e9diatement\", \"primaire\", \"r\\u00e9sident\", \"rassemblement\", \"v\\u00e9hicule\", \"fr\\u00e9quenter\", \"physiquement\", \"r\\u00e9ellement\", \"ordinateur\", \"envie\", \"c\\u00e9r\\u00e9monie\", \"\\u00e9lever\", \"masque\", \"afficher\", \"classe\", \"d\\u00e9sinfecter\", \"provincial\", \"enfant\", \"obligatoire\", \"distance\", \"salle\", \"respecter\", \"examen\", \"chemin\", \"rentrer\", \"uniquement\", \"\\u00e9tudier\", \"oublier\", \"lundi\", \"communal\", \"s\\u00e9curit\\u00e9\", \"reprendre\", \"\\u00e9tablissement\", \"pouvoir\", \"jour\", \"condition\", \"petit\", \"personnel\", \"\\u2019\", \"place\", \"faire\", \"d\\u00e9cider\", \"falloir\", \"semaine\", \"passer\", \"mesure\", \"bien\", \"travail\", \"heure\", \"dernier\", \"encontre\", \"migrer\", \"eric\", \"personnel_soigner\", \"remercier\", \"commentair\", \"secour\", \"dispara\\u00eetre\", \"tribunal_correctionnel\", \"ministre_sophie\", \"ecolo\", \"sophie_wilm\\u00e8\", \"st\\u00e9phanie\", \"invisible\", \"maintien\", \"arr\\u00eat\\u00e9_royal\", \"wilm\\u00e8\", \"soulever\", \"syndical\", \"droite\", \"parquet_namur\", \"strictement\", \"r\\u00e9fugier\", \"secr\\u00e9taire\", \"r\\u00e8glement\", \"cellule\", \"pascal_smet\", \"plainte\", \"criminel\", \"conscience\", \"syndicat\", \"vote\", \"texte\", \"tribunal\", \"camp\", \"individu\", \"infirmier\", \"appel\", \"salarier\", \"travailleur\", \"agent\", \"violence\", \"dossier\", \"ministre\", \"bruxellois\", \"proposition\", \"policier\", \"formation\", \"pr\\u00e9venir\", \"droit\", \"f\\u00e9d\\u00e9ral\", \"parquet\", \"soin\", \"bruxelle\", \"travail\", \"social\", \"anderlecht\", \"contact\", \"demander\", \"chambre\", \"politique\", \"jeune\", \"personnel\", \"vid\\u00e9o\", \"mercredi\", \"prendre\", \"condition\", \"mois\", \"gouvernement\", \"blesser\", \"prince\", \"riverain\", \"papa\", \"incendie\", \"carrefour\", \"tour_france\", \"b\\u00e9b\\u00e9\", \"habitation\", \"forc\\u00e9ment\", \"cyclisme\", \"fen\\u00eatre\", \"camion\", \"apercevoir\", \"fils\", \"\\u00e9tage\", \"toit\", \"angleterre\", \"comp\\u00e9tition_sportif\", \"h\\u00e9ritier\", \"hommage\", \"frer\", \"corps\", \"trac\", \"veger\", \"bateau\", \"percuter\", \"littoral\", \"entit\\u00e9\", \"voleur\", \"nuit\", \"poster\", \"accident\", \"ball\", \"police\", \"homme\", \"voiture\", \"victime\", \"soirer\", \"instruction\", \"apr\\u00e8smidi\", \"dimanche\", \"d\\u00e9c\\u00e9der\", \"midi\", \"femme\", \"intervenir\", \"policier\", \"jeune\", \"zone\", \"voitur\", \"voisin\", \"retrouver\", \"soir\", \"heure\", \"matin\", \"situer\", \"mardi\", \"petit\", \"samedi\", \"maison\", \"jeudi\", \"indiquer\", \"famille\", \"dernier\", \"d\\u00e9clarer\", \"mercredi\", \"place\", \"vendredi\", \"saison\", \"joueur\", \"club\", \"championnat\", \"football\", \"match\", \"league\", \"champion\", \"entra\\u00eenement\", \"pompier\", \"tennis\", \"reine\", \"virton\", \"f\\u00e9minin\", \"moto\", \"tournoi\", \"huis_clore\", \"playoff\", \"coach\", \"chien\", \"classemer\", \"club_bruge\", \"ligue_champion\", \"eupen\", \"ligue\", \"maillot\", \"toilette\", \"tenni\", \"braban\\u00e7on\", \"commission_licence\", \"disputer\", \"entra\\u00eeneur\", \"comp\\u00e9tition\", \"final\", \"monaco\", \"licence\", \"ao\\u00fbt\", \"bruge\", \"jouer\", \"sport\", \"sportif\", \"\\u00e9quipe\", \"formul\", \"prochain\", \"calendrier\", \"reprendre\", \"juillet\", \"professionnel\", \"d\\u00e9cision\", \"titre\", \"devoir\", \"dernier\", \"mois\", \"terrain\", \"raison\", \"coronavirus\", \"pouvoir\", \"semaine\", \"mouscron\", \"festival\", \"musicien\", \"lindic\", \"compl\\u00e9ter\", \"startup\", \"bruno\", \"temp\\u00eate\", \"jazz\", \"musical\", \"percevoir\", \"princip\", \"metteur_sc\\u00e8ne\", \"laurent\", \"concours\", \"pur\", \"laatste_nieuw\", \"change\", \"t\\u00e9ler\", \"litre\", \"foisci\", \"kayak\", \"coulisse\", \"senior\", \"concour\", \"peau\", \"sourir\", \"\\u00e9trange\", \"marketing\", \"excel_mouscron\", \"manager\", \"vendeur\", \"amateur\", \"concert\", \"d\\u00e9bloquer\", \"investisseur\", \"formation\", \"musiqu\", \"group\", \"antwerp\", \"lentrepri\", \"constructeur\", \"genk\", \"drame\", \"finaliser\", \"intense\", \"pareil\", \"sainttrond\", \"lufthanser\", \"clor\", \"julie\", \"boursier\", \"coalition\", \"capteur\", \"alexander\", \"com\\u00e9die\", \"laszlo_b\\u00f6l\\u00f6ni\", \"dembler\", \"conseil_surveillance\", \"carsten_spohr\", \"gille\", \"cin\\u00e9art\", \"m\\u00f6nchengladbach\", \"lantwerp\", \"ordinaire\", \"a\\u00e9ronautique\", \"edward\", \"repr\\u00e9sentant_syndical\", \"gr\\u00e8v\", \"croate\", \"stade\", \"allemand\", \"d\\u00e9part\", \"lufthansa\", \"installer\", \"supporter\", \"donne\", \"documentaire\", \"netflix\", \"masque_tissu\", \"michael_jordan\", \"chaud\", \"tristesse\", \"chambouler\", \"nick\", \"facteur_demeur\", \"jupiler_leagu\", \"roberto_martiner\", \"rouvrir_port\", \"remont\", \"cin\\u00e9mer\", \"last_danc\", \"deadline\", \"d\\u00e9poser_pr\\u00e9avis\", \"martiner\", \"bouquet\", \"soixantedeux\", \"dorer\", \"last_dance\", \"bernd_storck\", \"c\\u00e9r\\u00e9bral\", \"fra\\u00eechement\", \"circonstance_exceptionnel\", \"s\\u00e9lectionneur_diabl\", \"humidit\\u00e9\", \"outreatlantiqu\", \"bozar\", \"brugeois\", \"diffusion\", \"\\u00e9pisode\", \"net\", \"espn\", \"g\\u00e9n\\u00e9ration\"], \"Freq\": [617.0, 587.0, 997.0, 1035.0, 522.0, 405.0, 592.0, 665.0, 436.0, 780.0, 1117.0, 740.0, 563.0, 622.0, 283.0, 369.0, 602.0, 606.0, 343.0, 665.0, 402.0, 322.0, 629.0, 590.0, 301.0, 547.0, 332.0, 223.0, 673.0, 271.0, 207.00156102599524, 202.82134322014247, 155.39104872282238, 152.7621836976813, 118.53248170737828, 108.69987168210714, 559.6762372940909, 103.39191448092784, 94.03878659417198, 87.58969879332415, 87.51202710557672, 83.07346445591756, 81.96865631565493, 76.2553280357117, 75.80379040837626, 75.03133006911362, 70.16503938046469, 69.31591405852373, 67.82681483825954, 107.3470897871728, 66.79195580927467, 56.18203772066655, 67.20927897708044, 55.342699058407405, 54.31303233039974, 56.93923870826099, 51.45020296643112, 50.22918457658119, 48.844840112987136, 48.7337512220735, 208.16097447074418, 84.15732772561502, 118.97352663020156, 225.5560948596969, 953.1450082440035, 211.06390650543523, 258.0965862825104, 172.19584806951102, 390.7986918246272, 119.00698437182693, 458.0141056218603, 423.08908798007303, 128.99913350311581, 266.84467766632764, 159.52816063377009, 163.44881068563186, 222.06684157737874, 252.63502885958002, 117.28596462671773, 142.71248346720728, 144.46228551831894, 225.0632012476101, 354.74354301842305, 196.0105442610443, 372.9036916957927, 383.82918479792403, 207.79995246629952, 235.50688124982454, 203.01477923442647, 269.1041292259782, 313.1511379732201, 195.84385011698507, 241.84025877541467, 247.75171201808456, 248.05275061579457, 285.892834804381, 213.79256370420444, 252.0835977124685, 219.1175740838697, 222.70494395017084, 238.23841667919402, 197.62747660349643, 156.7261152809593, 135.99173780116547, 135.7326686713447, 101.60237513942351, 82.20670717679036, 76.34691629546553, 74.87833143643527, 71.82246648212785, 68.64295847226218, 69.29533664021213, 63.30513959136975, 63.52412810806738, 62.062607817537256, 60.426203412912294, 59.73073006643099, 55.70206485489262, 55.20184359922079, 53.52412981839869, 53.29807345649942, 168.2941430444125, 52.13419562620908, 49.56403941649415, 46.87147546769804, 46.600151474152575, 45.59677303823744, 45.424742931175814, 55.699318979009924, 42.9513673778707, 41.38466169150459, 88.32288029268081, 96.30244803503174, 322.0826954031276, 247.00428857122972, 71.06295983433424, 175.50688398775029, 62.18651956262101, 189.19852890642352, 89.18036031624142, 85.14931621939178, 105.54622620854207, 145.3650439861831, 112.99475859402676, 307.66874750584, 220.56508197889943, 124.94111431621093, 146.37432048485346, 105.12104141792254, 90.45551493051325, 152.5988213533478, 182.01331225594333, 322.78710759138454, 305.06568338265254, 448.59380849074296, 168.58438015919296, 201.85252109117081, 372.29507936798746, 255.75090592829787, 253.6778548310991, 241.78971954171186, 180.98069253556852, 222.53398639464743, 170.30677176538572, 207.91751212915221, 268.87011108956335, 238.4061975411437, 193.9322092193005, 219.0533036402919, 208.51704365481555, 181.90948013783952, 159.85003077265566, 168.25210951717708, 161.6814972194013, 170.93071123406116, 145.97865113548897, 151.99442629568682, 144.68810180082446, 113.38159949995048, 110.06809542340058, 94.63004103235424, 92.72515796671345, 92.99748028809134, 87.24567206756751, 85.58314490462912, 75.66447073027433, 72.98990141910114, 71.6061693682708, 195.71865369598495, 64.5943762312437, 64.76858234069819, 59.93637551456825, 64.33887541391906, 59.2864718882536, 59.2864718882536, 59.2864718882536, 58.8232603791749, 56.343594604102336, 64.10425474530564, 52.20910921501901, 50.7492540444639, 50.33299656908216, 49.30803098751614, 49.05952344195556, 63.382679773215806, 182.8432707308545, 252.02595305352085, 96.61706043477109, 117.76676295124642, 118.23157466265278, 512.8790872570393, 92.12596248197863, 271.5223088065707, 144.33774054655447, 447.21807927635575, 137.16284304978544, 80.20771091600598, 89.82968321587349, 571.1923205192454, 133.27417420857674, 182.5136844216825, 319.2379502189833, 137.47792233439537, 266.89633982160956, 335.3780449322512, 137.86111819005959, 227.20527565678375, 337.74393023109275, 284.0638862439352, 235.67354637467787, 198.19255542045863, 165.662667986423, 303.9441576668451, 274.50958201550765, 225.198145753142, 223.58257262390057, 175.86367543650994, 171.95804112840887, 221.39334080277933, 201.2056533479289, 239.9325208604132, 208.8190505787307, 187.15217817365107, 188.86108351892977, 187.86545867139208, 174.56858573537943, 173.23923287852762, 321.66580194910426, 206.87239412026693, 131.3632879213306, 108.51102456290643, 107.50718940964141, 100.51174745488692, 91.45680134011036, 88.47180173581515, 83.48549225553123, 83.46563114100562, 73.3369338759407, 68.50286044773233, 62.62033543618451, 61.58035630374495, 61.02370896878263, 58.527971065279054, 58.18889838144621, 57.5106189817193, 55.973823614128655, 55.970988632955056, 53.6244487214728, 48.855039670434664, 43.36868906237526, 41.48073781755428, 41.14814741159115, 40.68785288233258, 38.467404647833554, 38.39694033783252, 38.20054681395277, 37.307166263862456, 351.377346934398, 158.05989947532427, 118.11274025589145, 303.5263739271523, 177.97873714197803, 90.44159376953006, 245.92832948732172, 718.77290612048, 176.96914267165835, 154.57972857481107, 467.70157961173544, 153.27501987515973, 234.9937177460539, 103.60489062469527, 344.27017097952086, 116.09005835850525, 363.46047534664694, 535.2362249418653, 216.15581209890757, 328.6615282142916, 361.68270657930066, 118.24741404637011, 314.27415309824045, 332.4466911008903, 174.91177490146052, 215.62251071206248, 145.49092514905587, 163.02558426449139, 162.7447342957352, 179.40662536746436, 149.7434618946919, 160.20455867157216, 155.80689363468264, 153.13892453251668, 138.78297381247654, 124.52048343429782, 85.96483437387145, 75.37016105308095, 63.46825784577385, 62.93164749469667, 60.72972126127702, 52.97596975294382, 52.09790971394553, 51.1883456107425, 50.25780926749805, 46.591291797468834, 46.48714596645012, 45.24145770150668, 45.532012845942745, 44.5278570646601, 44.127095322469835, 43.570633476413136, 42.351986166793154, 40.533915117076695, 39.718469753434256, 39.490962480140375, 38.64336127147704, 38.55682544531404, 37.91348995986646, 38.0057447652638, 37.72558234542663, 37.47760359052324, 37.06667565731043, 37.00983560101469, 530.4922276298659, 161.84870204117934, 108.85010675051412, 105.60159936866339, 60.721144779562145, 568.2871848894791, 134.0951913147409, 143.36802929475058, 84.30877059969961, 57.31455272988347, 110.8228088245876, 277.83257367003546, 189.1595105196179, 69.01260353839481, 87.3739368070968, 99.60958756072935, 150.95157857605813, 91.02070611325149, 101.15805186041156, 249.12515787352984, 173.6428507773393, 251.10153217610403, 128.59800832300522, 87.99913768361715, 90.45712236949642, 123.58578205266727, 101.88070191749206, 161.18752604302642, 98.08142384890608, 221.03036835292087, 121.0038318349759, 150.0611347015531, 111.05036776343398, 113.73022817738472, 146.9682916551094, 142.53305037799015, 121.46427523884935, 117.05877742287662, 119.3373077735596, 106.0890837278603, 436.0488384611788, 199.19114572239178, 131.46238617180742, 115.88283983541315, 80.32560631735679, 66.18207559157253, 66.12421919743385, 78.87581367519985, 62.314045097754786, 60.666627005662114, 57.05149664966172, 56.82005124433394, 54.779016143272884, 296.77569234772966, 49.343949437737884, 48.03365618006391, 47.98898592003388, 46.99723397063331, 44.47649325933153, 42.370637899020586, 41.553069824001994, 40.769980019642226, 40.56634645145849, 155.9668474155638, 39.712749495724985, 39.25526004286069, 38.937868803426845, 37.44545619637799, 37.28502159326057, 36.547708494469575, 209.67280967398906, 175.60286897376824, 53.20633269697796, 101.00084594199834, 72.54949120806796, 52.77305814181815, 472.7571957095152, 118.00215496690146, 195.49234984119133, 123.97074257285895, 243.61495789736261, 95.52973052697531, 101.80855911678835, 166.00943887874806, 85.11991018605843, 110.8406604399966, 96.60114258941061, 326.2615538316096, 120.91957821549222, 265.27411710603195, 296.06899487459845, 77.77994083827369, 281.85189146911983, 271.9453095263537, 168.2906837028452, 193.24295795819515, 151.174502629644, 174.989636405501, 169.7556334591565, 189.09993410757681, 139.75482666949014, 147.66235102383888, 141.4762179824937, 146.90631956324552, 149.8733385391033, 149.21215206598134, 135.7470350513846, 133.4519418121574, 133.89017356059114, 86.42411804076495, 82.73648272362954, 52.11326801779124, 50.510395670827215, 50.238869046641156, 47.55337394482897, 45.945997038576046, 44.23264146315407, 39.690255218650954, 37.03817973386517, 36.389023589868785, 35.11521361987849, 34.72540180573232, 34.67786088143876, 33.84133883608547, 33.710125993058256, 36.954256661645985, 32.51192402451347, 31.479988363965802, 30.35643839327643, 30.20233817616447, 29.273089183722817, 28.925554872974487, 28.74030892308148, 28.365914692256823, 28.33265170858699, 27.936855419989868, 27.883438044249893, 27.856572723023337, 27.737074974837377, 113.7641679653287, 51.46267786840973, 70.74875942354245, 64.48531016224416, 37.91766792927018, 70.14933977140669, 78.14848106488861, 139.24419137949502, 43.150469704349824, 90.50246716413437, 99.15790222163697, 61.30587447106932, 122.0602482948123, 230.36772060472268, 117.453207581523, 111.20568631224262, 117.3881021166929, 89.72430724755341, 80.74096835980065, 116.57092969202601, 124.25663683671453, 81.95981892566131, 89.38451548565476, 113.09283739907745, 157.80981350591637, 117.7569790725612, 79.13859291865745, 102.64744495306569, 112.71147298388551, 66.45817750317337, 98.26266157159641, 123.80734755627427, 102.07957882055308, 88.01633391833212, 102.0326860342867, 106.21340315789877, 92.97887833952893, 97.9361296335038, 81.2289514804635, 72.24467730543893, 61.66942368905944, 59.74541459969003, 53.6324271979873, 52.30274394563611, 50.404783921917655, 48.0928898172225, 45.46815987363795, 43.972275479158284, 38.74220663109146, 38.39650064629103, 38.36342544798535, 38.36169856095102, 32.83858513584323, 32.56785174164501, 33.195687586865965, 31.8850173854679, 32.325590984171676, 31.031656022788752, 30.79094427557369, 30.36050471208427, 30.001813722630818, 135.46020099106656, 28.79720501947454, 28.036626159601482, 27.792468049850086, 27.386412427746766, 27.236185608313573, 27.16832314773256, 27.143185700558952, 120.85230792545354, 28.62121324312994, 113.92592461393923, 39.15206436928325, 419.8654018388007, 266.2474407262029, 141.08727350974343, 110.82628344233729, 54.97115746081021, 49.673769664533694, 90.29404623706404, 132.4064717917766, 77.41856920890814, 43.24819841604101, 137.60501939281755, 103.08805076075888, 119.00145066024241, 215.72741241747892, 127.63204171714227, 77.94507458402857, 76.26045798911838, 141.22539482636083, 120.02622841330394, 146.5919865705712, 107.77469864640327, 77.0501419364757, 123.42532513741764, 125.3151769447603, 97.45417939641894, 92.99280256562254, 105.1596827512007, 98.42460591234835, 80.48051532704817, 116.07036749805187, 94.32757012915636, 91.96531713274751, 88.94091783742266, 80.79823289523632, 616.7141458069593, 404.2828485543235, 585.8077620755578, 283.00536528558337, 222.60214761009453, 180.25734372641645, 166.778156007969, 111.30983868124682, 105.81402292883068, 77.54522515385773, 59.07605405713843, 57.95037257201127, 53.75833215427918, 50.146075461555, 47.24257728038399, 47.052083331392055, 59.7212351272629, 46.34868826395682, 43.10442343154614, 37.7904788602708, 36.91549483832427, 34.85861860323857, 34.57296477841583, 32.480543119663096, 32.1528298078472, 31.264148374768716, 30.416724204135853, 29.525901977550475, 29.37330740825511, 29.309441165989302, 115.52156339730574, 80.90911312665932, 154.81136784797224, 105.57471247008505, 43.323091506648154, 90.47832257829451, 202.94988325548485, 51.04375556198689, 201.21698654996374, 132.1269697520264, 161.7375453845361, 242.5152128730437, 70.23476830659489, 202.50384640704507, 70.16293941267708, 234.05925271811873, 115.57556456970677, 110.74945503786888, 138.28296588153614, 97.62917799785663, 149.043034124682, 165.02734448226593, 119.43241265076962, 82.2248530674526, 97.14854005864579, 102.85371349727205, 94.06475222472774, 90.52658440707533, 51.696782742971685, 35.80901078401761, 31.65031865947908, 27.813894387621005, 24.397715262775566, 23.76362022641317, 23.499512848216852, 19.986135070400273, 18.62583217301839, 17.66285008515012, 17.4023564397964, 15.935321389938437, 15.832280684989744, 15.668359491589362, 15.495664011373883, 14.453146921678677, 13.800288272479701, 13.001671248422994, 12.710770238133152, 12.38484082818869, 11.940454062700889, 11.640080827946033, 11.571629883036865, 11.555132699421046, 11.437167038710305, 11.18032374177183, 10.692930118076793, 10.328910798251048, 10.185818634886783, 9.662814498657808, 27.836539251157433, 21.66785245344312, 29.341077614477854, 22.062566831990022, 13.07820227878027, 20.083498119820003, 17.08071478813375, 14.565809302409283, 13.46177805067874, 33.53267353648374, 20.91046964060324, 19.877353502111042, 12.9400768017146, 12.891607233726157, 12.748633780914366, 11.925180899045998, 11.056231069603115, 10.631952404302105, 10.056844821064795, 9.624592013682477, 9.434360447257259, 9.091801784993098, 8.801837901735748, 8.601803618678847, 8.458571924809059, 7.521177771424805, 7.260508108183975, 6.961365749087712, 6.93781596848814, 6.738113031494624, 6.7261503942491805, 6.679789003721334, 6.637701882469597, 6.363629793143427, 6.2778733494518955, 6.224688508615873, 5.941624503626878, 5.92276720989918, 5.886537508527265, 8.609706554586074, 16.05824168604575, 14.66339818322705, 9.305948182337005, 7.849851704451189, 8.299718545761769, 7.812355482596305, 8.002247632925076, 11.33888424738004, 4.6829978929494365, 4.264832527893709, 3.986359142747802, 3.4155826182523117, 2.8531829954626207, 2.831973283968497, 2.821972695335667, 2.582444518348279, 2.4103873239598097, 2.3326187564046474, 2.180660828337841, 1.9815814635982116, 1.9380320097340136, 1.9066767432935237, 1.8837006260985776, 1.8728254234279327, 1.8165266398230724, 1.590030019352866, 1.5770796953436017, 1.463459658088572, 1.3792245976106499, 1.1436474349559835, 1.0972096517119485, 1.0181300460621059, 0.9704497746856057, 0.9588924437024283, 0.9429705510734948, 0.9349522122262601, 0.9117841711909677, 1.7604240343302182, 4.015369422541749, 4.230041896953365, 2.1618429807477937, 2.599340237840903, 1.2627181574384214], \"Total\": [617.0, 587.0, 997.0, 1035.0, 522.0, 405.0, 592.0, 665.0, 436.0, 780.0, 1117.0, 740.0, 563.0, 622.0, 283.0, 369.0, 602.0, 606.0, 343.0, 665.0, 402.0, 322.0, 629.0, 590.0, 301.0, 547.0, 332.0, 223.0, 673.0, 271.0, 207.80264823821312, 203.6877511367661, 156.19263797883136, 153.68958437284428, 119.3335693035609, 109.50095018545143, 563.8431670076669, 104.19863769995257, 94.8579588015639, 88.39094174794437, 88.31311571030783, 83.87500490692581, 82.76972111504506, 77.05641348524703, 76.60487983549716, 75.8324179084309, 70.96611132256334, 70.12133098350847, 68.62789132514457, 108.61658019871724, 67.5931038854438, 56.98315222931321, 68.17748548852646, 56.1438089852029, 55.1224265167864, 57.824063745122544, 52.25126822378288, 51.03065338492957, 49.64593125971711, 49.534847635528465, 213.5358477150071, 85.68711219403002, 122.84263264147032, 236.0287397460538, 1035.9221240457514, 220.93033957537958, 272.7108538538281, 180.90707337820876, 428.13121217114065, 125.447660466124, 538.5103944284978, 494.48118344541115, 138.25954418862173, 313.8831078808998, 178.74298903109056, 189.39489757283584, 274.9272036398467, 332.2501211951032, 130.40409487852307, 168.036758556637, 174.58098393648723, 354.82757219754507, 805.0105330066131, 303.9089326167096, 916.6292288782007, 1038.5935989720715, 356.4704196826908, 455.86082530420373, 353.7769164316871, 668.5574811759151, 1041.3038565516574, 362.98865478700674, 629.6896664361525, 696.0495795591111, 702.8334364610815, 1455.2335799425161, 506.1384718119437, 1020.602374652587, 574.4898398151842, 665.1915043687103, 1117.3179571594246, 198.4260427113766, 157.52477957881277, 136.8264285649943, 136.69145979864467, 102.40095699323, 83.0053765181927, 77.14547913209492, 75.67694722531627, 72.62101358948068, 69.44152975854274, 70.14913157265971, 64.10370289465025, 64.33908674421812, 62.8612457687215, 61.22476843458679, 60.52929891054863, 56.50062239668046, 56.00040326062686, 54.32293489858746, 54.09663968781133, 170.84865789195027, 52.93278856563456, 50.363324968814965, 47.67003338425673, 47.41558859747944, 46.3953316307359, 46.22332347303491, 56.7206576632901, 43.74997633152628, 42.183237619681755, 90.8869474927636, 99.33583362704263, 346.94627267321323, 282.5332826115295, 74.51168369057936, 199.90175604237115, 64.72380524264713, 227.67325102191037, 97.91031136362173, 93.58912071891575, 120.54559934694676, 177.97945632408744, 132.63983126359074, 465.286446532322, 313.63005183799106, 153.01072404983796, 192.55414713231715, 126.51075089434137, 104.11820472482859, 214.14031248339293, 279.27339976191377, 696.0495795591111, 716.4711536735575, 1325.3484590381577, 290.56483255617144, 398.104103983334, 1176.9813514783416, 629.6896664361525, 640.1733009614749, 624.3311718501052, 393.38669005092913, 662.9202942640818, 362.66470109236275, 584.7688707640228, 1183.7953365852268, 1020.602374652587, 602.8281144514029, 1123.5539813526052, 1038.5935989720715, 590.5570085116738, 318.2722538206931, 548.7629430788113, 702.8334364610815, 171.74109383284852, 146.77964568008545, 152.8965057613042, 145.57949979828743, 114.18045045082246, 110.87072285470889, 95.42890428714239, 93.52401227258045, 93.8386506684274, 88.04799790640688, 86.38201103999994, 76.48094343693633, 73.78877840597447, 72.40525858724912, 198.11218570270358, 65.39324784061071, 65.58980617145602, 60.7352156985394, 65.20274217138173, 60.08531173552767, 60.08531173552767, 60.08531173552767, 59.62212891359738, 57.14246299710474, 65.01620153461948, 53.007968940711265, 51.54811464500048, 51.13215920792911, 50.10689661769682, 49.85912652433492, 64.44678376524764, 192.13345628643748, 271.8076044889087, 100.16139103922583, 124.79084551237203, 125.38513424391444, 606.0085808266182, 96.86811405936906, 360.33513804692575, 175.27536141620547, 719.2090776763217, 167.61794728599733, 86.84286118547648, 100.66942033547268, 1183.7953365852268, 171.1193189979079, 273.04362379449026, 606.9924960878312, 184.09910069129043, 497.4690582343961, 700.6308681283097, 194.6641429656579, 461.8753332032165, 1041.3038565516574, 823.1908337118549, 618.0181716691651, 440.29822645372974, 307.79280815446367, 1266.036406700889, 1123.5539813526052, 680.9763214965346, 688.6137675173006, 380.6675239825332, 369.814620098072, 866.0243429566027, 681.9425452984914, 1325.3484590381577, 1176.9813514783416, 711.0798145189901, 805.0105330066131, 1020.602374652587, 582.3568895942363, 702.8334364610815, 322.46536491789925, 207.6719706609072, 132.17905886664187, 109.31059048704475, 108.30675647258654, 101.31134251325173, 92.25636236907864, 89.27359674923349, 84.28505281682887, 84.26519011509423, 74.13649264782505, 69.30243482374499, 63.41989044993002, 62.379913662973905, 61.82334451721523, 59.327528443965036, 58.98846624021865, 58.31022812958343, 56.77340108255697, 56.77055888024367, 54.42407557901876, 49.654610309601, 44.16831602421589, 42.280299840583325, 41.94771643778381, 41.48748813342181, 39.26699939758385, 39.19654745384526, 39.01867858771431, 38.10674611587345, 369.194214891452, 164.41634132413603, 123.4454309626992, 332.09518927977183, 191.3988497968916, 95.25051354157283, 294.05548548254467, 997.1145674254358, 216.41683437108742, 186.05992897194736, 740.1444292085395, 193.73206539268668, 334.74477905128384, 121.06728293072602, 602.8281144514029, 145.1594690051887, 665.1915043687103, 1117.3179571594246, 347.5386536155716, 679.9568535251004, 1266.036406700889, 162.5889493972876, 1176.9813514783416, 1455.2335799425161, 376.7995571577617, 692.568672592788, 287.6188046255711, 396.4192000391878, 412.8123258372999, 677.7142605293457, 362.98865478700674, 548.7629430788113, 501.8402688877013, 1038.5935989720715, 139.58041665193446, 125.31794232957441, 86.76234830291149, 76.16761133389872, 64.26577801205518, 63.72914202379011, 61.52716459274205, 53.77342012269333, 52.89535100764356, 51.98581861375304, 51.055269153242044, 47.38874393221054, 47.28467888592041, 46.038929719066296, 46.3429683553624, 45.32534862966067, 44.92462116573454, 44.368134810712945, 43.14943731886079, 41.33137440791983, 40.51668956250825, 40.288402058674045, 39.440823265859926, 39.354305290554926, 38.71099252368186, 38.80611136501225, 38.52306828744691, 38.27515627113993, 37.86412954541046, 37.80731299228315, 592.360460790928, 173.1804886450736, 115.51536715435495, 112.3732996206541, 63.20944609256084, 665.6112405788298, 146.7429219849337, 168.43956947140288, 95.22812856641849, 61.51233933773143, 132.54463340505424, 409.8968651890087, 259.1364751244884, 77.40467349306999, 103.92808070435784, 126.3767766564949, 229.61439736061646, 116.98833536996673, 141.35669986203447, 526.501069621539, 313.1355158042974, 677.7142605293457, 239.8361131293155, 127.8614571388366, 137.97479725919882, 262.5814096188993, 183.86130313359416, 547.1965561063269, 174.13328785774925, 1455.2335799425161, 323.546720772835, 644.3654329313257, 276.1320059112707, 302.77040765840115, 1041.3038565516574, 1117.3179571594246, 504.1555189289298, 504.4168214849, 692.568672592788, 271.30520092007504, 436.84899331708067, 199.99130741674438, 132.29195608209662, 116.68645530134951, 81.16005914423256, 66.98284100856682, 66.9243707167991, 79.8586998068503, 63.114205055207144, 61.46678543685526, 57.85167752728142, 57.62022323703231, 55.57923181936233, 301.2187093572853, 50.14411234270664, 48.833831039089844, 48.7892101508518, 47.79740524761645, 45.276680476988744, 43.17184862505431, 42.35322555649963, 41.570154805993646, 41.36653147280974, 159.1015317931861, 40.512925051149644, 40.055604514739045, 39.74445533875527, 38.24561144900499, 38.08520470437321, 37.34787777290134, 214.59114837885505, 180.64919456729845, 54.42611760025082, 104.90761088409094, 75.50731454727244, 54.7823397420549, 622.841800247091, 134.91457438759986, 240.28877902308696, 145.00712202190067, 317.5473315277869, 109.50915290721805, 120.75019641254863, 220.15825558935717, 97.65551167947464, 143.829695549408, 121.65370626637275, 673.4053209776299, 183.36498885467893, 624.3311718501052, 780.7622526988432, 95.20628729875867, 1325.3484590381577, 1266.036406700889, 474.2667717604287, 681.9425452984914, 402.3384902001469, 618.0181716691651, 584.7688707640228, 866.0243429566027, 427.95657371603704, 662.9202942640818, 658.5596340137212, 823.1908337118549, 1038.5935989720715, 1183.7953365852268, 574.4898398151842, 501.8402688877013, 1455.2335799425161, 87.22507951317539, 83.5370086639024, 52.91381788770263, 51.310895438466204, 51.03943167108625, 48.35389308830652, 46.746531515208076, 45.03318313752149, 40.49074832235966, 37.8594794701604, 37.206872954503005, 35.91595644877143, 35.5259463356251, 35.47843833866163, 34.64186047621233, 34.51062003435531, 37.85780738142974, 33.3124488753364, 32.28052972070187, 31.15699475554156, 31.002837291892497, 30.074032845063932, 29.72606497637454, 29.540836259407055, 29.16642761698393, 29.13321189077183, 28.737343416634452, 28.68396024808378, 28.657105657886525, 28.537618742605293, 130.91805100906095, 57.637146061843445, 83.10248220088967, 76.28876727546887, 41.14944141151583, 88.32812399832639, 101.71537974254399, 210.97268606489092, 49.391094885376354, 134.43077803188157, 156.0861846433808, 80.80955992955344, 218.67134904590023, 590.5570085116738, 226.84793270302544, 212.64689917892528, 237.11759920894696, 166.44245600752015, 141.90086301977638, 262.98650395604517, 321.747167948116, 155.03980208304202, 182.3065979444197, 291.98639698987347, 574.4898398151842, 334.9139926655149, 155.6039894613753, 286.5865653576188, 395.05997552224073, 107.3180305315121, 323.546720772835, 629.476341944075, 402.3384902001469, 261.1721320176881, 781.1881735382196, 1123.5539813526052, 474.2667717604287, 916.6292288782007, 668.5574811759151, 73.05691009110592, 62.4816800170784, 60.557648942493365, 54.444693257629694, 53.11496761373646, 51.21704004725822, 48.90513473545022, 46.28040662320552, 44.78451064638711, 39.55450419380348, 39.208815582572235, 39.17567277708605, 39.17394254961387, 33.65093975424291, 33.38008352358995, 34.02490317627775, 32.69729568659481, 33.15088526896213, 31.844068131548898, 31.603187648982114, 31.17277136984953, 30.814133286379075, 139.13510988113327, 29.609472622197334, 28.84888039784575, 28.604723920496436, 28.1986430739916, 28.048426662907836, 27.980619692877042, 27.9554121293531, 125.49776708014981, 29.4800515707435, 123.62712723524793, 41.09404001314499, 522.2653905277245, 343.71578975260024, 173.58048707055332, 146.3621226175129, 64.60063363362647, 57.8117886284026, 138.53648092375505, 249.58445866816297, 116.44586599258257, 50.83515987852187, 280.83735257408085, 184.95287326856376, 237.11759920894696, 629.476341944075, 285.9386066590373, 129.36687096292283, 131.61798367663965, 423.48487912919745, 322.2874224248986, 501.8402688877013, 276.4623551709171, 164.47232595079643, 543.3750056836361, 681.9425452984914, 341.2088691383773, 321.56198240543773, 504.1555189289298, 418.3369539806691, 226.33135451085258, 1455.2335799425161, 526.501069621539, 781.1881735382196, 584.7688707640228, 504.4168214849, 617.539076163777, 405.1077493327385, 587.508340535315, 283.83026626639787, 223.42705103511204, 181.08224292627756, 167.60305311603796, 112.13475050505987, 106.63892603519376, 78.37020051918678, 59.90095565660628, 58.775353183388766, 54.58325736357421, 50.970988233518774, 48.06750793305223, 47.876984899786926, 60.7811656132626, 47.17358655908217, 43.92936422910689, 38.61544065897418, 37.74040522516612, 35.68351919698357, 35.397860929112845, 33.305529410539194, 32.97773950529337, 32.08906061641228, 31.24172788303117, 30.350810222043226, 30.19825556530465, 30.13434823133726, 118.92874184119704, 83.7249957171534, 165.61966338762218, 117.50207766502845, 45.8690611389414, 105.77812802577898, 271.01939511800174, 55.69765277447809, 281.1677189866288, 171.9473364041294, 221.5434524017585, 402.0164066908995, 88.26169963662065, 547.1521048480726, 95.77824344056957, 780.7622526988432, 236.1779034686829, 255.3913189654425, 470.76734301584366, 211.9692581535456, 1020.602374652587, 1455.2335799425161, 916.6292288782007, 199.5048972764266, 584.4819265230245, 1117.3179571594246, 1325.3484590381577, 658.5596340137212, 52.532520361088245, 36.64470391329452, 32.48603884312308, 28.649581951930788, 25.233443836176004, 24.599337583932062, 24.33524711010803, 20.82265056320677, 19.461507760803936, 18.49853565882953, 18.238066300228642, 16.771119816396347, 16.667963005490385, 16.504065398683856, 16.33137436815468, 15.289693811707021, 14.636037045441924, 13.837465947894739, 13.54647448812674, 13.220541501168903, 12.776239500186623, 12.475779799712193, 12.407426215476503, 12.390861433975173, 12.272871431458992, 12.016068434839298, 11.528628888189957, 11.164635627010627, 11.021531095138698, 10.498532147883148, 45.18087009200995, 35.56693403270563, 60.71438377014054, 42.1090624132985, 19.557396752316755, 86.42682240599463, 166.44245600752015, 57.586075632434905, 72.20604586135003, 34.38440870778425, 21.7944407818486, 20.77188538197594, 13.791789938986152, 13.743375031226236, 13.600421644822363, 12.776947513120714, 11.908011447084888, 11.483690235359699, 10.908701520124724, 10.47633802320764, 10.286131696626102, 9.943511204047207, 9.653542357455347, 9.453497859477935, 9.310363855141203, 8.372925146682183, 8.112190508275665, 7.813204951148676, 7.789498030495439, 7.589798773151585, 7.577902783786908, 7.531477347680701, 7.489380173175954, 7.215324777293409, 7.129642819305333, 7.076418758376054, 6.793327657305903, 6.7744930657996205, 6.738266621527243, 12.784060996247087, 106.35511162133287, 147.59342344508275, 118.65449607276257, 48.77164756011434, 128.6144310569903, 77.48246682449874, 119.68704261451266, 12.210176038705502, 5.556463339520932, 5.135779426762088, 4.997148213759548, 4.286469499854517, 3.724151297740057, 3.703171761666571, 3.6928836970526584, 3.4533252100023684, 3.2814088686744673, 3.20347415707133, 3.0515548964930623, 2.852539602741336, 2.808940955250774, 2.777635824037876, 2.754595473048239, 2.7437657515564515, 2.6873894857862033, 2.4609451152157424, 2.4479612297522966, 2.3343519464109983, 2.2500807886683156, 2.0145589045344328, 1.968194569524376, 1.8893499349912615, 1.8413818877708223, 1.8297528193015795, 1.8138643961607244, 1.805867119264968, 1.7827017629456683, 5.014272353921623, 49.60320442943157, 60.73262541651286, 17.44602232873481, 38.6597981652532, 44.77890115244758], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.6361, -5.6565, -5.9229, -5.94, -6.1937, -6.2802, -4.6415, -6.3303, -6.4251, -6.4962, -6.4971, -6.5491, -6.5625, -6.6348, -6.6407, -6.6509, -6.718, -6.7302, -6.7519, -6.2928, -6.7673, -6.9402, -6.761, -6.9553, -6.9741, -6.9269, -7.0282, -7.0522, -7.0802, -7.0825, -5.6305, -6.5362, -6.1899, -5.5503, -4.1091, -5.6167, -5.4155, -5.8202, -5.0006, -6.1897, -4.8419, -4.9213, -6.109, -5.3822, -5.8966, -5.8723, -5.5659, -5.4369, -6.2042, -6.008, -5.9958, -5.5525, -5.0974, -5.6907, -5.0475, -5.0186, -5.6323, -5.5071, -5.6556, -5.3737, -5.2222, -5.6915, -5.4806, -5.4564, -5.4552, -5.3132, -5.6038, -5.4391, -5.5792, -5.563, -5.4956, -5.6519, -5.8838, -6.0257, -6.0276, -6.3173, -6.5291, -6.603, -6.6225, -6.6641, -6.7094, -6.7, -6.7904, -6.7869, -6.8102, -6.8369, -6.8485, -6.9183, -6.9273, -6.9582, -6.9624, -5.8126, -6.9845, -7.0351, -7.0909, -7.0967, -7.1185, -7.1223, -6.9184, -7.1783, -7.2154, -6.4573, -6.3708, -5.1635, -5.4289, -6.6748, -5.7707, -6.8082, -5.6955, -6.4477, -6.4939, -6.2792, -5.9591, -6.211, -5.2093, -5.5421, -6.1105, -5.9522, -6.2832, -6.4335, -5.9105, -5.7343, -5.1613, -5.2178, -4.8322, -5.8109, -5.6308, -5.0186, -5.3941, -5.4023, -5.4503, -5.7399, -5.5333, -5.8007, -5.6012, -5.3441, -5.4644, -5.6708, -5.549, -5.5983, -5.7348, -5.8641, -5.8129, -5.8527, -5.6285, -5.7863, -5.746, -5.7952, -6.039, -6.0687, -6.2198, -6.2402, -6.2372, -6.3011, -6.3203, -6.4435, -6.4795, -6.4986, -5.4931, -6.6017, -6.599, -6.6765, -6.6056, -6.6874, -6.6874, -6.6874, -6.6953, -6.7383, -6.6093, -6.8145, -6.8429, -6.8511, -6.8717, -6.8768, -6.6206, -5.5612, -5.2403, -6.199, -6.0011, -5.9972, -4.5298, -6.2466, -5.1658, -5.7976, -4.6668, -5.8486, -6.3852, -6.2719, -4.4221, -5.8774, -5.563, -5.0039, -5.8463, -5.1829, -4.9545, -5.8436, -5.344, -4.9475, -5.1206, -5.3074, -5.4806, -5.6599, -5.053, -5.1548, -5.3528, -5.36, -5.6001, -5.6226, -5.3699, -5.4655, -5.2894, -5.4283, -5.5379, -5.5288, -5.5341, -5.6075, -5.6151, -4.6864, -5.1278, -5.582, -5.7731, -5.7824, -5.8496, -5.9441, -5.9772, -6.0352, -6.0355, -6.1649, -6.233, -6.3228, -6.3396, -6.3487, -6.3904, -6.3962, -6.4079, -6.435, -6.4351, -6.4779, -6.5711, -6.6902, -6.7347, -6.7427, -6.754, -6.8101, -6.8119, -6.8171, -6.8407, -4.5981, -5.3969, -5.6883, -4.7444, -5.2783, -5.9552, -4.9549, -3.8824, -5.2839, -5.4192, -4.3121, -5.4277, -5.0004, -5.8193, -4.6185, -5.7056, -4.5642, -4.1772, -5.0839, -4.6649, -4.5692, -5.6871, -4.7097, -4.6534, -5.2956, -5.0864, -5.4798, -5.366, -5.3677, -5.2703, -5.451, -5.3835, -5.4113, -5.4286, -5.5053, -5.6137, -5.9842, -6.1158, -6.2876, -6.2961, -6.3318, -6.4683, -6.4851, -6.5027, -6.521, -6.5968, -6.599, -6.6262, -6.6198, -6.6421, -6.6511, -6.6638, -6.6922, -6.736, -6.7564, -6.7621, -6.7838, -6.7861, -6.8029, -6.8005, -6.8078, -6.8144, -6.8255, -6.827, -4.1644, -5.3515, -5.7482, -5.7785, -6.3319, -4.0956, -5.5396, -5.4728, -6.0037, -6.3896, -5.7303, -4.8112, -5.1956, -6.2039, -5.968, -5.8369, -5.4212, -5.9271, -5.8215, -4.9202, -5.2812, -4.9123, -5.5815, -5.9609, -5.9333, -5.6213, -5.8144, -5.3556, -5.8524, -5.0399, -5.6424, -5.4271, -5.7282, -5.7044, -5.448, -5.4786, -5.6386, -5.6755, -5.6562, -5.7739, -4.3583, -5.1418, -5.5573, -5.6835, -6.05, -6.2436, -6.2445, -6.0682, -6.3039, -6.3306, -6.3921, -6.3962, -6.4327, -4.7431, -6.5372, -6.5641, -6.5651, -6.586, -6.6411, -6.6896, -6.7091, -6.7281, -6.7331, -5.3864, -6.7544, -6.766, -6.7741, -6.8132, -6.8175, -6.8374, -5.0905, -5.2678, -6.4619, -5.8209, -6.1518, -6.47, -4.2775, -5.6653, -5.1605, -5.616, -4.9405, -5.8766, -5.8129, -5.324, -5.992, -5.7279, -5.8655, -4.6483, -5.6409, -4.8553, -4.7455, -6.0822, -4.7947, -4.8304, -5.3103, -5.1721, -5.4176, -5.2713, -5.3017, -5.1938, -5.4962, -5.4411, -5.4839, -5.4462, -5.4263, -5.4307, -5.5252, -5.5423, -5.539, -5.5925, -5.6362, -6.0984, -6.1296, -6.135, -6.19, -6.2243, -6.2623, -6.3707, -6.4399, -6.4575, -6.4932, -6.5043, -6.5057, -6.5301, -6.534, -6.4421, -6.5702, -6.6025, -6.6388, -6.6439, -6.6751, -6.6871, -6.6935, -6.7066, -6.7078, -6.7219, -6.7238, -6.7247, -6.729, -5.3177, -6.111, -5.7927, -5.8854, -6.4164, -5.8012, -5.6932, -5.1156, -6.2871, -5.5464, -5.4551, -5.9359, -5.2473, -4.6121, -5.2858, -5.3404, -5.2863, -5.5551, -5.6606, -5.2933, -5.2295, -5.6456, -5.5589, -5.3236, -4.9904, -5.2832, -5.6806, -5.4205, -5.327, -5.8552, -5.4642, -5.2331, -5.4261, -5.5743, -5.4265, -5.3864, -5.5194, -5.4675, -5.6545, -5.6827, -5.841, -5.8727, -5.9806, -6.0057, -6.0427, -6.0896, -6.1458, -6.1792, -6.3058, -6.3148, -6.3157, -6.3157, -6.4712, -6.4794, -6.4604, -6.5006, -6.4869, -6.5278, -6.5356, -6.5496, -6.5615, -5.0541, -6.6025, -6.6293, -6.638, -6.6527, -6.6582, -6.6607, -6.6616, -5.1682, -6.6086, -5.2272, -6.2953, -3.9228, -4.3783, -5.0134, -5.2548, -5.956, -6.0573, -5.4597, -5.0769, -5.6135, -6.1958, -5.0384, -5.3272, -5.1836, -4.5888, -5.1136, -5.6068, -5.6286, -5.0124, -5.1751, -4.9751, -5.2827, -5.6183, -5.1471, -5.1319, -5.3834, -5.4302, -5.3073, -5.3735, -5.5748, -5.2086, -5.416, -5.4414, -5.4748, -5.5708, -3.4634, -3.8857, -3.5148, -4.2423, -4.4824, -4.6934, -4.7711, -5.1755, -5.2261, -5.5369, -5.809, -5.8282, -5.9033, -5.9729, -6.0325, -6.0365, -5.7981, -6.0516, -6.1242, -6.2557, -6.2792, -6.3365, -6.3447, -6.4072, -6.4173, -6.4453, -6.4728, -6.5025, -6.5077, -6.5099, -5.1383, -5.4945, -4.8456, -5.2284, -6.1191, -5.3827, -4.5748, -5.9551, -4.5834, -5.004, -4.8018, -4.3967, -5.636, -4.577, -5.637, -4.4322, -5.1379, -5.1805, -4.9585, -5.3066, -4.8836, -4.7817, -5.1051, -5.4783, -5.3116, -5.2545, -5.3438, -5.3822, -4.1285, -4.4957, -4.6191, -4.7483, -4.8794, -4.9057, -4.9169, -5.0788, -5.1493, -5.2024, -5.2172, -5.3053, -5.3118, -5.3222, -5.3333, -5.4029, -5.4492, -5.5088, -5.5314, -5.5574, -5.5939, -5.6194, -5.6253, -5.6267, -5.637, -5.6597, -5.7043, -5.7389, -5.7529, -5.8056, -4.7475, -4.998, -4.6949, -4.98, -5.5029, -5.074, -5.2359, -5.3952, -5.474, -4.1076, -4.5799, -4.6306, -5.0598, -5.0636, -5.0747, -5.1415, -5.2171, -5.2563, -5.3119, -5.3558, -5.3758, -5.4128, -5.4452, -5.4682, -5.485, -5.6024, -5.6377, -5.6798, -5.6832, -5.7124, -5.7141, -5.7211, -5.7274, -5.7695, -5.7831, -5.7916, -5.8382, -5.8413, -5.8475, -5.4673, -4.8439, -4.9348, -5.3895, -5.5596, -5.5039, -5.5644, -5.5404, -4.1077, -4.992, -5.0856, -5.1531, -5.3076, -5.4875, -5.495, -5.4985, -5.5872, -5.6562, -5.689, -5.7564, -5.8521, -5.8743, -5.8906, -5.9027, -5.9085, -5.9391, -6.0722, -6.0804, -6.1552, -6.2145, -6.4018, -6.4432, -6.518, -6.566, -6.578, -6.5947, -6.6032, -6.6283, -5.9704, -5.1458, -5.0938, -5.765, -5.5807, -6.3027], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7493, 1.7489, 1.748, 1.7471, 1.7464, 1.7458, 1.7457, 1.7454, 1.7445, 1.744, 1.744, 1.7435, 1.7434, 1.7427, 1.7426, 1.7425, 1.7418, 1.7416, 1.7414, 1.7414, 1.7412, 1.739, 1.7388, 1.7388, 1.7384, 1.7377, 1.7377, 1.7373, 1.7369, 1.7368, 1.7277, 1.7351, 1.7211, 1.7078, 1.6699, 1.7075, 1.6981, 1.7038, 1.6619, 1.7004, 1.5912, 1.5972, 1.6838, 1.5908, 1.6394, 1.6058, 1.5396, 1.4792, 1.6471, 1.5898, 1.5638, 1.2979, 0.9337, 1.3146, 0.8538, 0.7577, 1.2135, 1.0927, 1.1978, 0.8431, 0.5516, 1.1361, 0.7962, 0.7201, 0.7117, 0.1258, 0.8913, 0.3548, 0.7893, 0.6589, 0.2077, 1.7796, 1.7786, 1.7775, 1.7766, 1.7758, 1.774, 1.7732, 1.773, 1.7726, 1.7721, 1.7714, 1.7711, 1.7709, 1.7709, 1.7705, 1.7704, 1.7694, 1.7693, 1.7688, 1.7688, 1.7686, 1.7684, 1.7677, 1.7668, 1.7663, 1.7663, 1.7662, 1.7655, 1.7652, 1.7645, 1.755, 1.7526, 1.7093, 1.6493, 1.7363, 1.6535, 1.7437, 1.5985, 1.6903, 1.6891, 1.6508, 1.5812, 1.6234, 1.37, 1.4316, 1.581, 1.5094, 1.5984, 1.643, 1.4448, 1.3555, 1.0152, 0.9298, 0.7003, 1.2393, 1.1045, 0.6326, 0.8826, 0.858, 0.835, 1.0072, 0.6921, 1.0278, 0.7496, 0.3014, 0.3295, 0.6495, 0.1487, 0.178, 0.6061, 1.095, 0.6014, 0.3142, 1.9474, 1.9467, 1.9463, 1.946, 1.9452, 1.9449, 1.9438, 1.9436, 1.9432, 1.943, 1.9429, 1.9414, 1.9413, 1.9411, 1.94, 1.9399, 1.9396, 1.9389, 1.9388, 1.9388, 1.9388, 1.9388, 1.9387, 1.9381, 1.9381, 1.937, 1.9366, 1.9364, 1.9361, 1.936, 1.9355, 1.9026, 1.8766, 1.9161, 1.8942, 1.8934, 1.7853, 1.902, 1.6692, 1.758, 1.4771, 1.7517, 1.8727, 1.8382, 1.2234, 1.7022, 1.5494, 1.3096, 1.6602, 1.3295, 1.2155, 1.6071, 1.2427, 0.8262, 0.8882, 0.9881, 1.154, 1.3327, 0.5254, 0.5429, 0.8456, 0.8273, 1.18, 1.1864, 0.5882, 0.7316, 0.2431, 0.2229, 0.6173, 0.5023, 0.2598, 0.7474, 0.5517, 2.2596, 2.2582, 2.2559, 2.2547, 2.2547, 2.2541, 2.2534, 2.253, 2.2525, 2.2525, 2.2512, 2.2505, 2.2494, 2.2492, 2.249, 2.2485, 2.2484, 2.2483, 2.2479, 2.2479, 2.2473, 2.2458, 2.2438, 2.243, 2.2428, 2.2426, 2.2415, 2.2415, 2.2409, 2.2409, 2.2126, 2.2226, 2.2179, 2.1721, 2.1894, 2.2103, 2.0833, 1.9347, 2.0608, 2.0767, 1.803, 2.0278, 1.9083, 2.1063, 1.7019, 2.0386, 1.6577, 1.5261, 1.7872, 1.5351, 1.0092, 1.9436, 0.9416, 0.7856, 1.4946, 1.0952, 1.5805, 1.3735, 1.3313, 0.933, 1.3766, 1.0308, 1.0924, 0.3478, 2.2781, 2.2774, 2.2746, 2.2733, 2.2713, 2.2712, 2.2707, 2.2689, 2.2686, 2.2683, 2.2681, 2.2668, 2.2668, 2.2663, 2.2661, 2.266, 2.2659, 2.2657, 2.2651, 2.2643, 2.2639, 2.2638, 2.2634, 2.2633, 2.263, 2.263, 2.2629, 2.2627, 2.2625, 2.2625, 2.1735, 2.2161, 2.2244, 2.2216, 2.2436, 2.1257, 2.1937, 2.1226, 2.162, 2.2131, 2.1048, 1.8949, 1.969, 2.169, 2.1103, 2.0458, 1.8644, 2.0328, 1.9492, 1.5355, 1.6942, 1.2909, 1.6605, 1.9102, 1.8616, 1.5302, 1.6934, 1.0616, 1.7098, 0.3992, 1.3003, 0.8266, 1.3729, 1.3046, 0.3258, 0.2247, 0.8605, 0.8231, 0.5253, 1.3448, 2.2841, 2.2819, 2.2796, 2.279, 2.2756, 2.2739, 2.2739, 2.2736, 2.2732, 2.2728, 2.272, 2.272, 2.2714, 2.2711, 2.2699, 2.2694, 2.2694, 2.2691, 2.2681, 2.2672, 2.2669, 2.2665, 2.2664, 2.266, 2.266, 2.2658, 2.2654, 2.2648, 2.2647, 2.2643, 2.2628, 2.2576, 2.2633, 2.248, 2.246, 2.2486, 2.0102, 2.152, 2.0796, 2.1292, 2.0209, 2.1494, 2.1153, 2.0036, 2.1486, 2.0254, 2.0554, 1.5613, 1.8696, 1.43, 1.3163, 2.0838, 0.7379, 0.7479, 1.2499, 1.0249, 1.3071, 1.0241, 1.0491, 0.7643, 1.1668, 0.7842, 0.748, 0.5625, 0.3501, 0.2148, 0.8432, 0.9614, -0.1, 2.6609, 2.6605, 2.6549, 2.6544, 2.6544, 2.6535, 2.6529, 2.6522, 2.6502, 2.6482, 2.6479, 2.6476, 2.6474, 2.6473, 2.6468, 2.6467, 2.646, 2.6458, 2.6451, 2.6441, 2.644, 2.6432, 2.6429, 2.6427, 2.6423, 2.6423, 2.6419, 2.6419, 2.6418, 2.6417, 2.5297, 2.5569, 2.5092, 2.5021, 2.5884, 2.4397, 2.4066, 2.2547, 2.5351, 2.2745, 2.2165, 2.394, 2.0871, 1.7288, 2.0119, 2.0219, 1.9671, 2.0523, 2.1063, 1.8566, 1.7188, 2.0327, 1.9574, 1.7217, 1.3781, 1.6249, 1.9941, 1.6434, 1.416, 2.1909, 1.4785, 1.044, 1.2986, 1.5825, 0.6346, 0.3114, 1.0408, 0.4338, 0.5623, 2.748, 2.7461, 2.7457, 2.7442, 2.7438, 2.7432, 2.7425, 2.7415, 2.7409, 2.7385, 2.7383, 2.7383, 2.7383, 2.7348, 2.7346, 2.7345, 2.7341, 2.734, 2.7334, 2.7332, 2.7328, 2.7325, 2.7324, 2.7314, 2.7307, 2.7304, 2.73, 2.7298, 2.7297, 2.7297, 2.7215, 2.7296, 2.6775, 2.7108, 2.541, 2.5038, 2.5519, 2.4811, 2.5978, 2.6075, 2.3311, 2.1253, 2.351, 2.5976, 2.0458, 2.1747, 2.0698, 1.6883, 1.9526, 2.2526, 2.2135, 1.661, 1.7715, 1.5286, 1.8172, 2.0009, 1.277, 1.0651, 1.5061, 1.5185, 1.1918, 1.3122, 1.7252, 0.2305, 1.0397, 0.6198, 0.876, 0.9278, 2.8328, 2.8321, 2.8313, 2.8313, 2.8305, 2.8296, 2.8292, 2.8268, 2.8264, 2.8236, 2.8203, 2.82, 2.819, 2.8179, 2.8169, 2.8168, 2.8166, 2.8165, 2.8152, 2.8126, 2.8121, 2.8108, 2.8106, 2.8091, 2.8088, 2.8081, 2.8074, 2.8066, 2.8065, 2.8064, 2.8051, 2.8, 2.7667, 2.7271, 2.7771, 2.6779, 2.5449, 2.7469, 2.4996, 2.5708, 2.5195, 2.3288, 2.6057, 1.8402, 2.523, 1.6295, 2.1195, 1.9987, 1.6091, 2.0589, 0.9103, 0.6574, 0.7962, 1.9478, 1.0397, 0.4488, 0.1887, 0.8498, 4.6321, 4.6251, 4.6221, 4.6185, 4.6144, 4.6136, 4.6132, 4.6071, 4.6042, 4.6019, 4.6012, 4.597, 4.5967, 4.5962, 4.5956, 4.5919, 4.5893, 4.5858, 4.5845, 4.5828, 4.5805, 4.5788, 4.5784, 4.5783, 4.5776, 4.576, 4.5729, 4.5703, 4.5693, 4.5652, 4.1638, 4.1525, 3.9209, 4.0017, 4.2457, 3.1887, 2.3714, 3.2735, 2.9685, 5.0768, 5.0604, 5.0578, 5.0381, 5.0379, 5.0372, 5.0328, 5.0276, 5.0248, 5.0205, 5.017, 5.0154, 5.0123, 5.0095, 5.0074, 5.0059, 4.9946, 4.9909, 4.9864, 4.986, 4.9828, 4.9826, 4.9818, 4.9811, 4.9762, 4.9746, 4.9736, 4.9679, 4.9675, 4.9667, 4.7065, 3.2113, 2.7927, 2.5563, 3.2752, 2.3612, 2.8075, 2.3967, 6.112, 6.015, 6.0002, 5.96, 5.9589, 5.9196, 5.9178, 5.917, 5.8954, 5.8775, 5.8688, 5.85, 5.8217, 5.8149, 5.8098, 5.806, 5.8041, 5.7944, 5.7492, 5.7463, 5.7191, 5.6966, 5.6198, 5.6017, 5.5677, 5.5455, 5.5398, 5.5318, 5.5277, 5.5155, 5.1393, 3.6721, 3.5217, 4.0979, 3.4865, 2.6175]}, \"token.table\": {\"Topic\": [1, 4, 8, 1, 5, 3, 1, 3, 1, 1, 2, 3, 6, 7, 1, 6, 1, 2, 3, 4, 5, 7, 9, 5, 6, 7, 1, 2, 7, 11, 1, 5, 11, 2, 3, 4, 5, 6, 7, 8, 9, 5, 2, 2, 10, 6, 1, 4, 5, 8, 3, 5, 6, 8, 9, 7, 9, 8, 2, 3, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 11, 1, 3, 9, 8, 1, 2, 3, 5, 6, 7, 1, 2, 3, 5, 6, 7, 8, 1, 7, 3, 5, 3, 5, 1, 3, 4, 5, 7, 5, 6, 1, 4, 5, 7, 8, 11, 3, 1, 1, 8, 1, 8, 3, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 7, 9, 1, 2, 3, 4, 9, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 8, 2, 3, 5, 6, 9, 12, 11, 12, 6, 9, 2, 5, 8, 9, 11, 1, 12, 10, 1, 2, 4, 7, 8, 1, 2, 4, 6, 7, 3, 8, 4, 3, 9, 8, 2, 7, 2, 5, 8, 9, 11, 8, 11, 7, 12, 3, 5, 7, 9, 9, 10, 1, 2, 3, 9, 3, 3, 12, 4, 1, 3, 4, 5, 8, 1, 6, 9, 4, 1, 4, 4, 5, 5, 2, 3, 4, 5, 6, 9, 1, 11, 3, 12, 12, 2, 7, 1, 6, 9, 1, 2, 2, 4, 11, 9, 10, 9, 9, 11, 1, 2, 11, 2, 7, 9, 1, 2, 4, 6, 7, 8, 2, 6, 8, 3, 3, 10, 3, 3, 2, 9, 8, 11, 1, 2, 4, 6, 2, 3, 10, 10, 10, 1, 2, 3, 4, 6, 7, 9, 2, 3, 5, 6, 7, 9, 1, 3, 4, 6, 7, 7, 11, 11, 2, 4, 6, 7, 4, 4, 4, 4, 2, 1, 2, 4, 5, 6, 7, 8, 9, 11, 4, 8, 9, 10, 3, 3, 1, 2, 4, 5, 1, 2, 7, 1, 2, 4, 6, 7, 2, 11, 1, 8, 12, 6, 12, 3, 1, 2, 3, 5, 6, 7, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 7, 8, 9, 10, 12, 1, 2, 4, 6, 7, 8, 9, 1, 5, 2, 7, 2, 4, 6, 5, 9, 1, 2, 3, 4, 6, 12, 5, 2, 3, 4, 5, 7, 8, 9, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 1, 5, 7, 10, 11, 1, 2, 3, 5, 7, 11, 7, 4, 10, 1, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 9, 1, 2, 3, 5, 6, 7, 9, 1, 2, 4, 5, 7, 8, 9, 11, 4, 8, 4, 8, 4, 8, 1, 5, 9, 5, 3, 5, 11, 1, 12, 2, 3, 5, 4, 6, 4, 7, 11, 1, 6, 1, 3, 7, 1, 7, 3, 4, 6, 7, 8, 1, 4, 8, 6, 6, 6, 8, 9, 9, 11, 1, 1, 2, 1, 6, 2, 7, 6, 4, 8, 9, 12, 2, 5, 8, 9, 1, 7, 1, 2, 3, 4, 5, 5, 6, 10, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 3, 6, 7, 8, 3, 5, 7, 8, 8, 5, 10, 3, 5, 8, 3, 8, 1, 2, 9, 5, 11, 2, 1, 5, 7, 10, 9, 8, 2, 3, 7, 8, 9, 10, 5, 9, 2, 2, 12, 8, 6, 1, 2, 4, 5, 6, 7, 8, 9, 5, 3, 6, 11, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 2, 3, 5, 10, 1, 2, 3, 4, 5, 6, 8, 9, 11, 6, 12, 8, 6, 1, 3, 4, 5, 6, 8, 3, 5, 6, 9, 3, 8, 5, 7, 8, 5, 1, 4, 4, 4, 9, 12, 1, 8, 4, 7, 6, 1, 2, 4, 1, 2, 3, 4, 6, 8, 9, 8, 1, 2, 4, 5, 6, 7, 8, 9, 4, 6, 7, 4, 4, 4, 7, 3, 2, 3, 6, 11, 6, 8, 11, 1, 2, 3, 5, 9, 1, 2, 3, 4, 5, 7, 8, 1, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 2, 1, 2, 4, 5, 6, 7, 8, 9, 3, 6, 7, 8, 9, 4, 3, 6, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 1, 2, 3, 5, 9, 11, 12, 10, 10, 1, 5, 1, 2, 3, 5, 7, 5, 11, 2, 7, 12, 12, 11, 10, 9, 11, 5, 5, 1, 9, 9, 9, 2, 10, 10, 10, 8, 1, 2, 3, 11, 11, 1, 2, 4, 5, 6, 7, 8, 5, 1, 5, 9, 7, 3, 4, 5, 6, 8, 4, 4, 8, 10, 2, 1, 2, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 4, 5, 6, 9, 12, 2, 4, 6, 2, 6, 12, 9, 1, 3, 5, 6, 7, 8, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 9, 4, 12, 3, 8, 7, 1, 1, 2, 4, 5, 8, 1, 2, 3, 5, 6, 7, 7, 2, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 9, 1, 2, 4, 5, 9, 1, 4, 5, 7, 8, 9, 10, 6, 10, 10, 3, 10, 3, 4, 8, 4, 1, 5, 8, 2, 4, 1, 7, 11, 6, 1, 2, 4, 5, 7, 8, 9, 2, 6, 2, 12, 12, 12, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 8, 2, 4, 6, 1, 5, 2, 1, 11, 6, 1, 6, 8, 9, 12, 2, 1, 2, 4, 5, 7, 9, 11, 8, 2, 11, 6, 2, 3, 7, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 4, 1, 5, 1, 4, 5, 8, 1, 2, 5, 7, 1, 2, 4, 5, 8, 10, 10, 8, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 6, 7, 7, 1, 4, 1, 2, 3, 4, 6, 8, 9, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 7, 1, 2, 3, 5, 9, 9, 1, 2, 4, 5, 6, 9, 5, 7, 8, 7, 8, 1, 2, 3, 5, 7, 9, 3, 8, 1, 2, 3, 4, 5, 6, 7, 9, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 5, 6, 8, 3, 10, 1, 2, 3, 6, 7, 9, 5, 1, 2, 4, 8, 1, 3, 6, 7, 9, 1, 2, 3, 7, 3, 5, 8, 2, 4, 6, 7, 1, 2, 5, 1, 6, 1, 2, 3, 5, 7, 9, 2, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 9, 10, 5, 5, 6, 1, 2, 3, 4, 5, 7, 8, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 5, 1, 2, 3, 4, 5, 6, 7, 6, 4, 3, 9, 5, 1, 1, 3, 5, 7, 12, 5, 8, 1, 3, 4, 5, 6, 8, 1, 3, 4, 6, 9, 11, 1, 2, 3, 4, 7, 2, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 6, 8, 9, 1, 2, 4, 5, 6, 7, 8, 8, 12, 12, 3, 8, 5, 7, 3, 1, 2, 6, 7, 5, 1, 2, 4, 7, 8, 2, 6, 11, 9, 1, 7, 11, 3, 6, 2, 3, 4, 6, 7, 8, 9, 11, 1, 2, 4, 5, 7, 9, 4, 3, 4, 1, 2, 3, 4, 5, 6, 8, 9, 4, 6, 3, 7, 8, 7, 7, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 7, 8, 4, 5, 7, 8, 9, 2, 4, 5, 6, 8, 1, 2, 7, 1, 2, 6, 7, 4, 7, 9, 4, 1, 3, 4, 5, 7, 8, 1, 7, 8, 10, 12, 5, 7, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 7, 10, 3, 2, 5, 9, 10, 6, 9, 1, 1, 2, 4, 8, 11, 10, 4, 2, 3, 5, 7, 7, 5, 9, 11, 4, 7, 1, 7, 9, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 12, 5, 7, 2, 5, 1, 2, 3, 4, 6, 7, 8, 10, 9, 9, 1, 2, 5, 6, 7, 9, 2, 4, 4, 5, 7, 3, 1, 2, 3, 6, 9, 9, 8, 2, 1, 4, 5, 6, 8, 11, 8, 1, 3, 9, 8, 4, 5, 2, 4, 1, 2, 3, 6, 7, 9, 1, 2, 7, 5, 7, 7, 1, 12, 1, 2, 3, 4, 5, 8, 5, 10, 1, 4, 6, 4, 2, 2, 4, 5, 6, 2, 4, 1, 2, 3, 4, 5, 8, 1, 3, 4, 5, 10, 2, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 11, 1, 7, 8, 3, 6, 7, 8, 9, 1, 2, 5, 6, 8, 5, 6, 7, 8, 4, 9, 4, 5, 2, 4, 5, 6, 1, 4, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 5, 8, 2, 8, 1, 5, 8, 8, 2, 7, 3, 1, 2, 3, 4, 5, 6, 7, 9, 2, 3, 4, 6, 9, 6, 5, 6, 2, 7, 1, 2, 8, 6, 6, 1, 2, 5, 1, 2, 3, 5, 6, 7, 8, 9, 1, 3, 1, 4, 6, 1, 4, 5, 6, 4, 7, 8, 12, 1, 2, 3, 6, 8, 9, 4, 6, 8, 5, 10, 2, 4, 6, 2, 5, 6, 1, 2, 3, 4, 6, 8, 9], \"Freq\": [0.99645448235192, 0.07279955622421004, 0.9221277121733272, 0.15395261695936524, 0.8371173547165485, 0.9819371539536186, 0.06990238568095437, 0.9271263785052896, 0.9921038994278681, 0.6341108122080619, 0.21418854101250087, 0.011273081105921099, 0.12682216244161237, 0.014091351382401375, 0.01837353175445664, 0.9737971829862021, 0.05226153123644783, 0.013065382809111957, 0.034841020824298546, 0.15242946610630614, 0.6576242680586352, 0.07839229685467174, 0.013065382809111957, 0.025626867676591836, 0.33314927979569386, 0.6342649749956479, 0.8972110891838976, 0.02300541254317686, 0.06901623762953059, 0.859257503194398, 0.8062689869395033, 0.08807980529591213, 0.1016305445722063, 0.0703054952048813, 0.4650978913553686, 0.0486730351418409, 0.0162243450472803, 0.13790693290188255, 0.0703054952048813, 0.08923389776004165, 0.10005012779156185, 0.9888231728103529, 0.9797281366432374, 0.5105874106762468, 0.4776462874068115, 0.9895782687093466, 0.07090277420596407, 0.013505290324945537, 0.8947254840276418, 0.018569774196800115, 0.19596715184697147, 0.5378672891119004, 0.008339027738168999, 0.1542720131561265, 0.10006833285802799, 0.5076990652582832, 0.4884193539193611, 0.9652834227615739, 0.9949414557451999, 0.9895654696513949, 0.23940209151196692, 0.1845771850588447, 0.12792478172395177, 0.02558495634479036, 0.2942269979650891, 0.005482490645312219, 0.018274968817707397, 0.10416732226093217, 0.44098801872084786, 0.10434646076774992, 0.23477953672743732, 0.01987551633671427, 0.0919242630573035, 0.05589988969700888, 0.008695538397312493, 0.04347769198656246, 0.9888202612105054, 0.05165681959368408, 0.19924773271849575, 0.7490238841084191, 0.980656119591405, 0.004739950079094221, 0.2227776537174284, 0.004739950079094221, 0.004739950079094221, 0.09953895166097865, 0.6588530609940967, 0.1248580883079705, 0.8644021498244112, 0.007218315301009848, 0.007218315301009848, 0.15880293662221664, 0.17323956722423636, 0.6496483770908863, 0.9862903885936855, 0.9852039739115962, 0.9946883256430205, 0.9666844920996073, 0.9960193585010914, 0.9912133740289057, 0.0038589704499129383, 0.13506396574695284, 0.07717940899825877, 0.7293454150335453, 0.05402558629878114, 0.9928219276961554, 0.9829251356826297, 0.33524180410517224, 0.5457075107182848, 0.04058981484681458, 0.06915301788716557, 0.009019958854847684, 0.8478865093869773, 0.9809845772087841, 0.9863863003825579, 0.024334429023773866, 0.9490427319271807, 0.9840087036600575, 0.9788592988285013, 0.9910628439086286, 0.12262069165969754, 0.12061051638658775, 0.5367167979203155, 0.10251893892859958, 0.04221368073530571, 0.0482442065546351, 0.02814245382353714, 0.3528574298467268, 0.23049557917407154, 0.24614651356243442, 0.01849655882261068, 0.029879056559601866, 0.12093903845553136, 0.13849331657419361, 0.30614312084821743, 0.10022542646816643, 0.2915648769983023, 0.16036068234906628, 0.49638657760225746, 0.07433717407085298, 0.2272352252847665, 0.4823468908461029, 0.03125540273433591, 0.003378962457766045, 0.12586635155178516, 0.0025342218433245336, 0.010136887373298134, 0.04223703072207556, 0.9914485689639199, 0.985533057861496, 0.4687525405366229, 0.4384214937960179, 0.022058943084076372, 0.00827210365652864, 0.060662093481210023, 0.8126958978622597, 0.9051128736433486, 0.560946323600218, 0.9853269733894816, 0.9603203713965072, 0.05936847280827186, 0.8489691611582876, 0.08905270921240778, 0.9156579758666121, 0.07181631183267546, 0.39886146161083885, 0.39886146161083885, 0.9451311464368318, 0.18151530532375493, 0.20891384197639717, 0.08904524412108733, 0.38700433021857183, 0.133567866181631, 0.07494007019343348, 0.24245316827287303, 0.05289887307771775, 0.11020598557857865, 0.5157640125077481, 0.9815538099882304, 0.9723337214033139, 0.9946796961779328, 0.26101961261706064, 0.7308549153277698, 0.9700325657003487, 0.07290499936556705, 0.9234633252971826, 0.1709572149800364, 0.7778553281591657, 0.00854786074900182, 0.03419144299600728, 0.9520285648530332, 0.9762375950243268, 0.9222905915189795, 0.9611024045333366, 0.8101163524345637, 0.2515886647031965, 0.12113528300524276, 0.6149945137189248, 0.9898804741621228, 0.9970747789609632, 0.9394783733489763, 0.028526542233891602, 0.13122209427590137, 0.8215644163360781, 0.01141061689355664, 0.994397029598632, 0.9779092960767025, 0.699876670089877, 0.9863774044216176, 0.051684546422578116, 0.2584227321128906, 0.08614091070429687, 0.5627872832680728, 0.03445636428171875, 0.14906808050648768, 0.8447191228700969, 0.9840623168227098, 0.9910798361196425, 0.2706210979473494, 0.7257565808588007, 0.06351754799897842, 0.9354402523485913, 0.9974629145383009, 0.13043412933511714, 0.7548528335989757, 0.019426359688208935, 0.008325582723518115, 0.024976748170554345, 0.06105427330579951, 0.9890229280380317, 0.9294325239065656, 0.9843700260760638, 0.7120121183969301, 0.5430704008990772, 0.8301370457516389, 0.16690586105059407, 0.028596590606896996, 0.9627518837655321, 0.9803816302249876, 0.06917497575368238, 0.9280975913619053, 0.9940552751947159, 0.9866823038506762, 0.9545320108846779, 0.9974326483025915, 0.0017021034953969138, 0.9808449611370913, 0.9788441229365412, 0.9323002548436925, 0.9827466156074205, 0.9528706973638907, 0.04026214214213623, 0.9912554924627355, 0.9926811872694465, 0.9623569681139601, 0.02796230853305155, 0.4601070767711209, 0.17031587924676853, 0.20336224387673854, 0.07880286950223618, 0.0559246170661031, 0.2126905481989717, 0.6598860597968097, 0.11997928359941994, 0.9956848194202733, 0.9955055096739681, 0.951118688190802, 0.9878947380019417, 0.9819371539536186, 0.060379303975492585, 0.9358792116201351, 0.9734937091560656, 0.9554605899194074, 0.12253660044765215, 0.5027142582467781, 0.06283928228084726, 0.31105444729019394, 0.0949914287034032, 0.3799657148136128, 0.5224528578687175, 0.8962857682843278, 0.9184775060480648, 0.06958109225638441, 0.2973010305500061, 0.010542589735815821, 0.025302215365957968, 0.35423101512341154, 0.19609216908617427, 0.04638739483758961, 0.04623347609316912, 0.7089133000952598, 0.01541115869772304, 0.06678168769013317, 0.01541115869772304, 0.14897453407798938, 0.259920931774866, 0.33040796412059237, 0.19971325831289138, 0.18796541958860366, 0.020558717767503527, 0.9811610510514441, 0.8986458398982066, 0.9628398978820807, 0.11165910711853713, 0.30706254457597715, 0.21982886713962, 0.3594027510377914, 0.969473141601203, 0.9969268740742331, 0.997158642308482, 0.9735485495173657, 0.9966685902991522, 0.2130100912412356, 0.08055003450298825, 0.47882520510109683, 0.12798505482141467, 0.0026850011500996083, 0.0026850011500996083, 0.0008950003833665361, 0.09218503948675322, 0.0017900007667330721, 0.00718725849179496, 0.9702798963923196, 0.02156177547538488, 0.9671627130074489, 0.9893669312878809, 0.9939864152095762, 0.1835295621771013, 0.0691996709848087, 0.7210806295373544, 0.026075238342101827, 0.968719063090373, 0.024421488985471588, 0.9770700619339872, 0.9199533226282469, 0.011583882341593875, 0.03668229408171394, 0.0028959705853984687, 0.027994382325518534, 0.23466721575254418, 0.7040016472576326, 0.9909553313986158, 0.9691698011120352, 0.50807984915925, 0.9906854741515259, 0.7260594230871937, 0.989310320308669, 0.032906396004340706, 0.2986888252701695, 0.10378171047522838, 0.192375853563838, 0.08606288185750646, 0.2860325191146538, 0.8959191578573501, 0.1965320234098071, 0.015117847954600548, 0.08452251356435761, 0.2281420691330628, 0.15186565445303277, 0.09208143754165787, 0.03779461988650137, 0.07971228921516653, 0.11338385965950411, 0.2469130057489635, 0.23319561654068774, 0.1842049407968458, 0.03331365950581253, 0.037232913565319894, 0.11267855421083652, 0.0019596270297536785, 0.003919254059507357, 0.14599221371664906, 0.12095992726711743, 0.3830397696792052, 0.04031997575570581, 0.18143989090067614, 0.18143989090067614, 0.08063995151141162, 0.18831300735150833, 0.10417315300296205, 0.10817981273384521, 0.036059937577948405, 0.016026638923532625, 0.5288790844765766, 0.016026638923532625, 0.1584371955356679, 0.8374537478313875, 0.9719500520479328, 0.9770572927441887, 0.8519311199622899, 0.09047056141192458, 0.05277449415695601, 0.025225189080078175, 0.9753739777630228, 0.02913161417049541, 0.10820313834755438, 0.00416165916721363, 0.0416165916721363, 0.8115235376066579, 0.9008879122733924, 0.9958417042601198, 0.1253268496934285, 0.5848586319026663, 0.09190635644184757, 0.03342049325158093, 0.016710246625790466, 0.008355123312895233, 0.06684098650316186, 0.06684098650316186, 0.0921625439726837, 0.3967675621874857, 0.10153500607160068, 0.17182847181347807, 0.05467269557701575, 0.0031241540329723285, 0.06716931170890507, 0.06873138872539122, 0.042176079445126434, 0.42838441801266186, 0.19206905789557271, 0.23779978596594717, 0.5579148824585684, 0.009146145614074891, 0.9459103000873352, 0.23575354273830915, 0.07985200641136277, 0.10266686538603785, 0.12167924786493375, 0.44488975000616404, 0.01520990598311672, 0.962865649764383, 0.3067892969594353, 0.6647101434121098, 0.2079216194704611, 0.07652670716621136, 0.3118824292056916, 0.1718241160901727, 0.09240960865353826, 0.023102402163384564, 0.01588290148732689, 0.09962910932959593, 0.17291474075848962, 0.14721119821330875, 0.1051508558666491, 0.09346742743702142, 0.327135996029575, 0.01635679980147875, 0.1378644554696066, 0.08709185250052519, 0.28251747274560607, 0.04035963896365801, 0.1720595134766473, 0.048856405061270224, 0.07647089487850992, 0.2931384303676213, 0.018993313740441643, 0.05508060984728077, 0.11395988244264986, 0.4729335121369969, 0.0531812784732366, 0.17853714916015145, 0.10446322557242904, 0.0018993313740441643, 0.859026464313304, 0.14041778743582856, 0.9299951394111816, 0.06792099332778292, 0.3263318940186382, 0.6612514694588195, 0.09043381599725638, 0.8914190434015272, 0.012919116571036626, 0.972830969434733, 0.716365606136622, 0.1938401051899095, 0.07585047594387763, 0.976052864048698, 0.7289252002892241, 0.0158204202349068, 0.0158204202349068, 0.9650456343293148, 0.0264875000785238, 0.9667937528661187, 0.9832430591398441, 0.9675631715683609, 0.8832195799575903, 0.9892025985531678, 0.9718026926104355, 0.8248321022889147, 0.12601601562747308, 0.040096004972377794, 0.9955131352872204, 0.9859549624945846, 0.07546057438880045, 0.08348829506846007, 0.7594223762958002, 0.009633264815591546, 0.07064394198100468, 0.12899069741996155, 0.8330649208372517, 0.03224767435499039, 0.9833169762357294, 0.9771835158854287, 0.9823462078904024, 0.9649536106190431, 0.9940085102227784, 0.9674530205249672, 0.023887728901851042, 0.9966235027244995, 0.9132714197994566, 0.0864221036638872, 0.9895677513474154, 0.9715058718261635, 0.9859443483318806, 0.982730070817381, 0.9838240842921696, 0.02586666375560087, 0.2586666375560087, 0.6207999301344209, 0.07759999126680261, 0.982135784701925, 0.9435973990746277, 0.05194114123346574, 0.9608014214562801, 0.9931839787505757, 0.00532062845759237, 0.4420954173518592, 0.5074049676424748, 0.002511905780408291, 0.010047623121633164, 0.040190492486532656, 0.11871153830414785, 0.8766390520921687, 0.9525141095097119, 0.8147007693739985, 0.10675389391797221, 0.005618625995682748, 0.07304213794387573, 0.08422718617594704, 0.1728109509472017, 0.32529120178296794, 0.09003595763635719, 0.015974121516127888, 0.14086270791494593, 0.05953990746920395, 0.0246872787067431, 0.08567937904104958, 0.9924058915146167, 0.8687279122483638, 0.10507787770644698, 0.1708958890170786, 0.2551891315727998, 0.0011547019528180987, 0.0808291366972669, 0.21823866908262066, 0.0854479445085393, 0.056580395688086836, 0.02771284686763437, 0.05128821714191739, 0.3363903653719876, 0.22476306923957914, 0.07542384873811381, 0.010559338823335932, 0.22325459226481686, 0.04374583226810601, 0.036203447394294624, 0.04418300779232292, 0.5036862888324812, 0.061856210909252085, 0.030928105454626043, 0.35346406233858335, 0.23145069345023803, 0.18872133465942484, 0.08545871758162635, 0.4913876260943515, 0.9699897233730801, 0.9919824972513778, 0.9824066278494169, 0.9455821820543818, 0.016026816644989523, 0.040067041612473805, 0.9941365189685643, 0.9886134639740687, 0.01702097562650375, 0.08510487813251875, 0.9021117082046988, 0.981633317119242, 0.9558527183566443, 0.9910547762543755, 0.9460569550278587, 0.0476695364936518, 0.0036668874225885997, 0.9392435074361838, 0.9980886332557604, 0.9859812629407109, 0.00600808245676703, 0.204274803530079, 0.5407274211090327, 0.01201616491353406, 0.13217781404887466, 0.1021374017650395, 0.19260902599870774, 0.7930959894064437, 0.9914790644480703, 0.9878878144963014, 0.5292825757048681, 0.973579224870201, 0.9873392244449877, 0.25485849812739636, 0.2517504676624281, 0.021756213254777737, 0.06837667022930147, 0.009324091394904746, 0.3853957776560628, 0.0062160609299364965, 0.98095017838245, 0.9774336691707227, 0.9212041025357088, 0.06909030769017815, 0.9425897622796626, 0.9237384273359452, 0.4023588211545553, 0.11666910055782645, 0.09872000816431468, 0.05085576178161666, 0.1435927391480941, 0.05235151948107597, 0.1211563736562044, 0.010470303896215194, 0.0014957576994593135, 0.30058469296034207, 0.11427980339386806, 0.32459305501787733, 0.027849699986740955, 0.1411691688983076, 0.013444682752219772, 0.0057620068938084735, 0.07298542065490733, 0.9827825407143155, 0.540120976502269, 0.2631358603472593, 0.18004032550075633, 0.38431629562804276, 0.4065494697552849, 0.07622802557911591, 0.017468922528547398, 0.0047642515986947446, 0.009528503197389489, 0.038114012789557956, 0.06511143851549485, 0.8904367157024259, 0.9602736756225572, 0.02233194594471063, 0.982482545079447, 0.9852782570240978, 0.035867986520682994, 0.09166263221952321, 0.3108558831792526, 0.003985331835631444, 0.265024567069491, 0.2929218899189111, 0.9524629574517147, 0.01040943122898049, 0.031228293686941466, 0.005204715614490245, 0.9827689214748758, 0.9623783411511547, 0.00872814135818241, 0.2123847730491053, 0.7738952004255071, 0.9830731625636783, 0.9798032492910634, 0.9864267871332895, 0.9933791993812805, 0.9849856137111166, 0.9871479000874549, 0.5513091287951998, 0.9796375706275451, 0.980913708589091, 0.9154001919127375, 0.08130199072909182, 0.9728561860940502, 0.8510042756615164, 0.06546186735857819, 0.08331510391091769, 0.5177018662275118, 0.22375250150511103, 0.04606669148634639, 0.13820007445903917, 0.024130171730943346, 0.030711127657564258, 0.019742867779862738, 0.9790084101746094, 0.258165096275455, 0.05497960383643948, 0.11713046034719715, 0.23904175581060644, 0.014342505348636386, 0.04302751604590916, 0.2342609206943943, 0.03824668092969703, 0.18114275811295577, 0.011321422382059736, 0.7924995667441814, 0.9847534909941673, 0.9863818349562443, 0.22612116336994714, 0.7668456844719946, 0.9955776551691643, 0.1010773044141491, 0.1477283679899102, 0.6842155991111631, 0.06220141810101483, 0.12108257097862805, 0.8648755069902003, 0.9391914608459601, 0.15112131968335676, 0.3317297261341978, 0.003685885845935531, 0.3907038996691663, 0.12163423291587253, 0.06488139269172212, 0.12976278538344424, 0.03244069634586106, 0.021627130897240707, 0.05406782724310177, 0.1405763508320646, 0.5568986206039481, 0.7636518173717121, 0.23140964162779154, 0.986514673106672, 0.26532339544845, 0.04465839329330347, 0.46234571880125946, 0.06304714347289901, 0.1418560728140228, 0.005253928622741585, 0.005253928622741585, 0.007880892934112376, 0.005253928622741585, 0.9799955399440122, 0.9762861250795055, 0.9851517011109162, 0.22017015748596325, 0.04760435837534341, 0.1844668887044557, 0.24000530680902302, 0.02578569411997768, 0.027769209052283653, 0.2082690678921274, 0.045620843443037434, 0.20175500100253674, 0.14774185112784186, 0.19698913483712246, 0.3431423639098262, 0.10961492180452782, 0.9922079415312615, 0.2347353395968571, 0.04623574870847185, 0.7148758069540648, 0.9972655439582109, 0.03159466804294698, 0.07740693670522009, 0.240119477126397, 0.28593174578867014, 0.05924000258052558, 0.21484374269203943, 0.04186293515690474, 0.03238453474402065, 0.017377067423620836, 0.9925993442471684, 0.03387277083294457, 0.35989819010003604, 0.07621373437412528, 0.03810686718706264, 0.49115517707769624, 0.8749644925265774, 0.6094942995652671, 0.9618637225607999, 0.9565430831127881, 0.9857487749606313, 0.9803040116962757, 0.020649436296941034, 0.5816257890305058, 0.16519549037552828, 0.15487077222705775, 0.07571459975545046, 0.9856170553978408, 0.8315633994580494, 0.9082252226227, 0.08548002095272471, 0.7200367962897961, 0.44442848676195246, 0.8628988671874678, 0.9694581070477306, 0.9964018965954012, 0.9635484667947871, 0.9909970386228629, 0.9872474881811084, 0.14180625314473685, 0.8508375188684212, 0.9703515304577978, 0.9887603115366322, 0.9833264251115637, 0.011706266965613853, 0.9773266516411766, 0.9076784032589749, 0.9626208387547701, 0.9955771288300199, 0.9828576745769382, 0.8201486314502151, 0.16402972629004303, 0.9166993873241172, 0.2108685446587333, 0.0029699795022356808, 0.14255901610731267, 0.03415476427571033, 0.48410665886441595, 0.0059399590044713615, 0.11731419033830938, 0.9864219463635674, 0.9961374494260872, 0.9885587346599155, 0.9660613120019078, 0.9814715356684414, 0.3016525749542701, 0.0964044311709523, 0.021768742522473104, 0.28921329351285696, 0.28921329351285696, 0.9971677069595913, 0.9967642688670567, 0.37626544078013185, 0.6197313142260995, 0.9912351905824167, 0.807486480278681, 0.18914097736257393, 0.9575105143685306, 0.04236772187471374, 0.2097998597792941, 0.023924545413428276, 0.03312629364936223, 0.1159420277727678, 0.13066482495026213, 0.11410167812558102, 0.0956981816537131, 0.22636300660397524, 0.04968944047404334, 0.907314955942077, 0.980310782440541, 0.01167036645762549, 0.3228905158664026, 0.4111808912986221, 0.12108394344990099, 0.007567746465618812, 0.13369685422593233, 0.7442166498671459, 0.009959540715120728, 0.0033198469050402424, 0.985994530796952, 0.022142362768796366, 0.9742639618270401, 0.7788496482454751, 0.9940234729325825, 0.11213099874243239, 0.08319396680890145, 0.01446851596676547, 0.285753190343618, 0.11574812773412375, 0.39064993110266766, 0.9677337352733447, 0.978646644567205, 0.11264891479529625, 0.09472749653240821, 0.1484917513210723, 0.16257286567048435, 0.12416982653572427, 0.011520911740428024, 0.13057033305818427, 0.11776932001326425, 0.09728769914139221, 0.369730759346155, 0.2012336684982979, 0.0876184872408857, 0.14731459942698363, 0.017331129344351017, 0.1444260778695918, 0.03273657765044081, 0.9599253366910906, 0.16141304701571496, 0.24555389067284297, 0.3005030130611715, 0.032626041418070045, 0.020605920895623187, 0.17858464776206762, 0.0497976421644227, 0.012020120522446859, 0.9709566880229527, 0.8004565461929025, 0.13769997019243246, 0.8458712454677993, 0.9935716076923108, 0.9884966087233872, 0.8504942610923218, 0.053852256706719066, 0.02228369243036651, 0.06870805166029674, 0.0037139487383944184, 0.022013116113485297, 0.3081836255887942, 0.008466583120571268, 0.14393191304971156, 0.12699874680856904, 0.38946282354627837, 0.9772981699117703, 0.9862992570670618, 0.03090053176728523, 0.9579164847858421, 0.4069257102530856, 0.012000490114702257, 0.12000490114702257, 0.10145868915157362, 0.09054915268366248, 0.025091933876195627, 0.1069134573855292, 0.0076366755275378, 0.12982348396814258, 0.028146123132062228, 0.10608923334392685, 0.49147461161370193, 0.04546681429025436, 0.11474957892302293, 0.08443836939618668, 0.05412715986935043, 0.03247629592161026, 0.04546681429025436, 0.043602374898012955, 0.9374510603072785, 0.24909343100112677, 0.12135320997490791, 0.01916103315393283, 0.555669961464052, 0.054289593936143014, 0.9923643137457414, 0.7020273793844514, 0.07468376376430334, 0.02389880440457707, 0.1971651363377608, 0.9777914857882993, 0.9898630342228413, 0.9941170952568856, 0.9730499933603353, 0.9850385316144517, 0.7293429798564678, 0.2604796356630242, 0.9800067596462788, 0.9609750389014762, 0.03649272299625859, 0.9738925400709223, 0.2610663537238342, 0.5547660016631477, 0.17948311818513601, 0.04199452424216242, 0.9448767954486544, 0.9486027842833694, 0.04782871181260686, 0.9346567857606263, 0.9892472603620246, 0.126750971458363, 0.039836019601199806, 0.1919371853512354, 0.4019816523393798, 0.0688076702202542, 0.0217287379642908, 0.1521011657500356, 0.9682358405425218, 0.02200536001233004, 0.8597948413314799, 0.11463931217753065, 0.8998529630236147, 0.8123732687261019, 0.22833381341627768, 0.09998048634795591, 0.6323090217681536, 0.03918154194717191, 0.16992622673994875, 0.3160627817363047, 0.17757290694324646, 0.26678417598171955, 0.012744467005496156, 0.005097786802198463, 0.016142991540295134, 0.012744467005496156, 0.022940040609893082, 0.03187307705200347, 0.9641605808231051, 0.11859356242738574, 0.007412097651711609, 0.8746275229019698, 0.9330278119824457, 0.06509496362668225, 0.9823778684080107, 0.9908507851105354, 0.8415568846946251, 0.9674312580760845, 0.05754037599703549, 0.7973452102446346, 0.03288021485544885, 0.10686069828020876, 0.5537505995496637, 0.9960844409563818, 0.29020799447497647, 0.1458799544419668, 0.23123524693460693, 0.23278716134356403, 0.012415315271656749, 0.07604380603889759, 0.009311486453742562, 0.9918322019829292, 0.9978528891391726, 0.923747852349674, 0.9950432474813584, 0.973534497714156, 0.9910076549103648, 0.5288964439988085, 0.4643968776574905, 0.9676533704818446, 0.5834986257349193, 0.0673267645078753, 0.03366338225393765, 0.03366338225393765, 0.053300355235401276, 0.06171620079888569, 0.07293732821686491, 0.0701320463623701, 0.022442254835958433, 0.9743419770594506, 0.08503496046519683, 0.07774624956817996, 0.34499898245879856, 0.05223576142862091, 0.09110888621271089, 0.17857341697691334, 0.06681318322265466, 0.0716723238206659, 0.029154843588067483, 0.001214785149502812, 0.9985568530188731, 0.3050176407551213, 0.6882449329859147, 0.2708322805857434, 0.3368889343871442, 0.37652292666798465, 0.013211330760280164, 0.8606356458854172, 0.015839919862921787, 0.11087943904045251, 0.005279973287640596, 0.1431281672075717, 0.20657673617587669, 0.26412311268201377, 0.3703625770010361, 0.014755481155419763, 0.9154408581850851, 0.932116361469027, 0.9574928810990504, 0.3562964583027076, 0.4640474033539297, 0.04884709508988734, 0.0014366792673496276, 0.10344090724917318, 0.025860226812293295, 0.2155943377404802, 0.16230135537766488, 0.033913716049064305, 0.39485255114267725, 0.014534449735313272, 0.1138531895932873, 0.06540502380890972, 0.08529952996180654, 0.18383519388320374, 0.022060223265984447, 0.4838542303005922, 0.0691220329000846, 0.07941680375754401, 0.07647544065541276, 0.10190424480542287, 0.007456408156494356, 0.1864102039123589, 0.07456408156494357, 0.3753058772102159, 0.2535178773208081, 0.9939409469312607, 0.9740753237723558, 0.023415272206066245, 0.10118154450943984, 0.12757673003364153, 0.2947462383535856, 0.0014663991957889833, 0.28301504478727374, 0.1832998994736229, 0.0087983951747339, 0.9736465214411976, 0.05985270719741146, 0.3556960884874738, 0.0017100773484974702, 0.008550386742487351, 0.00513023204549241, 0.2907131492445699, 0.013680618787979762, 0.15219688401627485, 0.11286510500083304, 0.9939600223899601, 0.9761553062349726, 0.5738079297188925, 0.23178448392585804, 0.16394512277682644, 0.005653280095752635, 0.02543976043088686, 0.9751219560630117, 0.7614745153138226, 0.08427385940232028, 0.02708802623646009, 0.03611736831528012, 0.01504890346470005, 0.07524451732350025, 0.0421241774756892, 0.15317882718432438, 0.804188842717703, 0.49342604846846533, 0.5018606817756186, 0.015453718671778919, 0.2101705739361933, 0.0958130557650293, 0.37397999185704983, 0.3028928859668668, 0.9952762591299463, 0.9775507219954115, 0.9837160539020254, 0.0995964488431941, 0.3387788297772284, 0.18108445244217108, 0.01735392669237473, 0.055079854284493704, 0.21277423161955103, 0.024144593658956146, 0.07092474387318368, 0.8299689888624041, 0.1580893312118865, 0.18334677587275708, 0.19491720347637767, 0.24475904546120483, 0.06230230248103396, 0.06942256562172355, 0.10769398000293014, 0.09434348661413713, 0.011570427603620592, 0.03204118413310318, 0.20573400183065818, 0.7912846224256084, 0.9916600081373159, 0.9922908600257428, 0.9944029122310117, 0.9540209702847356, 0.1699710175213952, 0.1955580524170891, 0.13159046517785433, 0.11879694773000739, 0.01279351744784695, 0.37101200598756157, 0.973361476063597, 0.13391573847551938, 0.7046518619783282, 0.015942349818514213, 0.14348114836662793, 0.34065370879646906, 0.043071158583461604, 0.06264895793958052, 0.11746679613671347, 0.4346271457058398, 0.18810525878556647, 0.009405262939278323, 0.2821578881783497, 0.5219920931299469, 0.8173349108388996, 0.0477275860343883, 0.1312508615945678, 0.7582282811061628, 0.020773377564552404, 0.09867354343162392, 0.11425357660503822, 0.03921293776798094, 0.8169362034996028, 0.13724528218793328, 0.018254057871725536, 0.9674650672014534, 0.01201902779322511, 0.009014270844918832, 0.021033298638143943, 0.8533509733189828, 0.05258324659535985, 0.049578489647053574, 0.16913216374628517, 0.09161325536257113, 0.06342456140485693, 0.5708210526437124, 0.10570760234142823, 0.05303772497352178, 0.4256975293927406, 0.10886690915617628, 0.17725765977992805, 0.04745480655525633, 0.14934306768860078, 0.0334975105095927, 0.004187188813699088, 0.9156494677009471, 0.9680205222138699, 0.8820923110067501, 0.10501098940556548, 0.1293008180864253, 0.014637828462614183, 0.002439638077102364, 0.15369719885744892, 0.6782193854344571, 0.019517104616818912, 0.002439638077102364, 0.9794183870282743, 0.2771685361833311, 0.10436593029125431, 0.06330392493076081, 0.04790567292057575, 0.12660784986152163, 0.11120959785133656, 0.05646025737067856, 0.04448383914053462, 0.16595893833199454, 0.005132750670061687, 0.9917027206060496, 0.5399617795630781, 0.0082647211157614, 0.005509814077174267, 0.41323605578807, 0.0165294422315228, 0.011019628154348534, 0.005509814077174267, 0.9911394197250823, 0.9857337802484761, 0.988097424912252, 0.9868081918458315, 0.9771781484010056, 0.9827291153364022, 0.03623850224332653, 0.3044034188439429, 0.6522930403798776, 0.9796347326556325, 0.7011296172989038, 0.9432845734514439, 0.05339346642177984, 0.009084374304502272, 0.04542187152251136, 0.036337497218009086, 0.018168748609004543, 0.7540030672736886, 0.13626561456753408, 0.2177359361474826, 0.08325197558580218, 0.020492793990351303, 0.3791166888214991, 0.29970711210888784, 0.8856751260534055, 0.8951400044684807, 0.03356775016756803, 0.05035162525135204, 0.011189250055856009, 0.005594625027928004, 0.1291146104196196, 0.08502669466657876, 0.7683893888387118, 0.015745684197514587, 0.22088387781975505, 0.13710033795708934, 0.07997519714163545, 0.030466741768242076, 0.4722344974077522, 0.06093348353648415, 0.06847942259386464, 0.03778175039661497, 0.20307690838180548, 0.2904472061739776, 0.33295167537016945, 0.06847942259386464, 0.23619985297046597, 0.2202762673769514, 0.46443791314417465, 0.01592358559351456, 0.02388537839027184, 0.03184717118702912, 0.00796179279675728, 0.990791436718045, 0.6243221895782152, 0.6554035787783007, 0.9893384362238412, 0.0100952901655494, 0.9846705008408335, 0.9600078682140453, 0.9921465033122411, 0.9851166350868379, 0.009206697524176055, 0.9812689510421005, 0.9755748035620726, 0.9792272058019438, 0.06877483803469668, 0.6619578160839555, 0.15044495820089898, 0.0042984273771685426, 0.11605753918355065, 0.9911395242132789, 0.9862845156902942, 0.9578802435936179, 0.999127057404811, 0.9954251521598395, 0.8706022836665518, 0.10123282368215719, 0.13792426000275604, 0.8551304120170875, 0.08499192905867593, 0.03223831791880811, 0.20222217603615997, 0.10257646610529854, 0.22566822543165677, 0.2842833489203988, 0.05861512348874202, 0.005861512348874202, 0.001658847648321842, 0.32181644377443736, 0.5706435910227137, 0.001658847648321842, 0.1028485541959542, 0.001658847648321842, 0.9697187615648266, 0.9497449278677453, 0.04129325773338023, 0.004542375780407957, 0.09766107927877107, 0.4496952022603877, 0.12491533396121882, 0.022711878902039784, 0.1476272128632586, 0.08630513982775118, 0.0635932609257114, 0.9846702668654181, 0.986187831026298, 0.9411004000717663, 0.04785256271551354, 0.007975427119252258, 0.9840302266069686, 0.9816919109988016, 0.8554420555553811, 0.09100447399525331, 0.006066964933016887, 0.04651339781979614, 0.2626945094487761, 0.04099856505847951, 0.09718178384232179, 0.2080297560374701, 0.025813911333116727, 0.2141036175276152, 0.004555396117608834, 0.00759232686268139, 0.1381803489008013, 0.9684556690381955, 0.42280919534508715, 0.2746284025839585, 0.06915103662186005, 0.023708926841780588, 0.04939359758704289, 0.09285996346364064, 0.06717529271837834, 0.18393185484222718, 0.7145045130409594, 0.04244581265589858, 0.03537151054658215, 0.01414860421863286, 0.2432020084154851, 0.03648030126232276, 0.06688055231425839, 0.18848155652200094, 0.4681638661998088, 0.2746973910160934, 0.3702443096303868, 0.3523292623902068, 0.6449300397734459, 0.3422077762063182, 0.006580918773198427, 0.0032904593865992135, 0.4827033195300413, 0.4881885845247009, 0.027426324973297802, 0.9939096795640581, 0.08687897215884909, 0.1458325604094967, 0.14272973997525207, 0.05585076781640299, 0.19547768735741045, 0.37233845210935324, 0.09287834596217999, 0.015479724327029999, 0.8513848379866499, 0.046439172981089995, 0.8170064034071223, 0.9810367781052458, 0.9744972279917451, 0.8940152799140225, 0.08940152799140226, 0.009933503110155806, 0.06822771502010305, 0.12345967479828172, 0.5393238425398623, 0.10071710312491404, 0.06497877620962196, 0.051983020967697566, 0.003248938810481098, 0.051983020967697566, 0.9906206572652265, 0.9541464216328891, 0.9937115912105229, 0.18610349348355187, 0.011631468342721992, 0.7676769106196515, 0.029078670856804982, 0.2663134448812611, 0.7312335266231237, 0.9796271573682441, 0.4607206861336367, 0.159841870699425, 0.12223201877014853, 0.10342709280551028, 0.15043940771710587, 0.9756360275195565, 0.9774071983348737, 0.9089951687465235, 0.05106714431160245, 0.030640286586961468, 0.9642870362416255, 0.9851954306675939, 0.15487374746574006, 0.7356503004622652, 0.10324916497716004, 0.994479317568835, 0.9603312048537836, 0.06110692863466409, 0.8707737330439632, 0.0687452947139971, 0.042028518103979, 0.714484807767643, 0.05136818879375211, 0.19613308448523534, 0.051254849097431956, 0.38761479629932916, 0.044847992960252964, 0.0016017140342947486, 0.08969598592050593, 0.4244542190881084, 0.5465219069216694, 0.9266433469070883, 0.04877070246879412, 0.8793352936503096, 0.11613862368966353, 0.17412878242991942, 0.16841964202238108, 0.4781405091313361, 0.005709140407538342, 0.11418280815076684, 0.0071364255094229275, 0.04995497856596049, 0.960492514595602, 0.9884414874108224, 0.9849592440265698, 0.09022334912941946, 0.05513649113464522, 0.12029779883922594, 0.19548392311374213, 0.1253102071241937, 0.4110174793673553, 0.15983378076716734, 0.8365768099728332, 0.9868167264727395, 0.14440001889464057, 0.8543667784599567, 0.9778581772124041, 0.1179416308655974, 0.15096528750796467, 0.23116559649657092, 0.033023656642367276, 0.46233119299314185, 0.960254186718475, 0.978674209228848, 0.9947296929226526, 0.3193889337062984, 0.6215136007257699, 0.020141644467964764, 0.00863213334341347, 0.02589640003024041, 0.0057547555622756465, 0.9814920306355049, 0.9869892407428518, 0.9896615362247946, 0.9816825369930338, 0.9794162959275259, 0.0817756647999149, 0.9131615902657163, 0.9664186275461577, 0.02013372140721162, 0.3812077861471897, 0.06614564325841649, 0.03829484609697796, 0.2367317758722274, 0.27502662196920535, 0.0017406748225899074, 0.28267336212982364, 0.04463263612576163, 0.6769283145740513, 0.1441889860440453, 0.8389177369835362, 0.9878799888198495, 0.9907004505430773, 0.8055526642595061, 0.0033002833017181468, 0.03300283301718147, 0.8465226668907047, 0.02805240806460425, 0.02805240806460425, 0.059405099430926644, 0.9914320024946471, 0.9596592834094423, 0.9912253787538892, 0.12288092902924368, 0.8704065806238094, 0.9956360144558534, 0.9936417046099358, 0.8742332857811086, 0.024775842107156925, 0.08494574436739517, 0.014157624061232528, 0.8804324858591791, 0.12005897534443351, 0.1083971306321124, 0.02064707250135474, 0.05677944937872555, 0.7897505231768189, 0.015485304376016057, 0.9705749274793645, 0.1102236051816095, 0.08266770388620712, 0.7991211375666688, 0.3655080302408363, 0.6185520511767999, 0.9836187341611, 0.25177590157706864, 0.011894924483956, 0.007929949655970667, 0.11300178259758199, 0.231951027437142, 0.08128198397369933, 0.16058148053340598, 0.142739093807472, 0.22922883855205667, 0.188445793656292, 0.26298032398303434, 0.043595668681679495, 0.06890928275491275, 0.07031559464787014, 0.094222896828146, 0.037970421109849876, 0.0042189356788722085, 0.9972047320338473, 0.23913290798238318, 0.7583929367441296, 0.3752314584366255, 0.0038288924330267906, 0.33694253410635755, 0.19527351408436633, 0.08423563352658939, 0.12174449850571407, 0.6516911390599989, 0.007161441088571416, 0.06803369034142845, 0.15039026285999973, 0.11137296141503358, 0.012374773490559288, 0.7548611829241165, 0.11137296141503358, 0.9882497553996503, 0.9893143540392031, 0.9558879504876562, 0.040503726715578656, 0.046046225304473484, 0.9507191224629525, 0.9793308473200942, 0.9902340541302839, 0.9550521689575757, 0.04073682237259802, 0.003662418430077176, 0.20875785051439902, 0.6702225727041231, 0.021974510580463055, 0.08423562389177504, 0.014649673720308704, 0.013904162656440323, 0.1640691193459958, 0.6215160707428824, 0.05839748315704935, 0.044493320500609036, 0.04032207170367694, 0.013904162656440323, 0.04032207170367694, 0.17474815642599892, 0.12156393490504273, 0.11396618897347756, 0.007597745931565171, 0.577428690798953, 0.39422766911179946, 0.6029364351121639, 0.13826438907413013, 0.04032711347995462, 0.8123032858105146, 0.9658237151027397, 0.086749610999738, 0.8848460321973276, 0.9819371539536186, 0.006589867297834278, 0.17957388386598408, 0.5255419170022837, 0.026359469191337113, 0.10543787676534845, 0.032949336489171394, 0.0757834739250942, 0.04777653790929852, 0.9872946172879707, 0.7772354447111027, 0.029219377620718148, 0.05259487971729267, 0.1344091370553035, 0.9857065266281906, 0.012570589217203594, 0.9805059589418803, 0.9927859217190299, 0.9773413348325473, 0.09792311827758232, 0.4511457949217186, 0.4476485406975192, 0.9892360146804552, 0.9980565519663119, 0.9507643719403529, 0.016583099510587552, 0.027638499184312586, 0.8506351354890714, 0.1465513716572932, 0.7441644173467782, 0.08147785591388083, 0.005431857060925389, 0.016295571182776164, 0.09234157003573161, 0.059750427670179275, 0.029951660703525184, 0.968437029413981, 0.004660024458392507, 0.018640097833570027, 0.9786051362624264, 0.14324209154101505, 0.8178661355728924, 0.0184828505214213, 0.0184828505214213, 0.0658624581527217, 0.1317249163054434, 0.7244870396799385, 0.0658624581527217, 0.06716143806727679, 0.007462382007475198, 0.22884638156257273, 0.047261752714009585, 0.044774292044851186, 0.604452942605491, 0.17855963594771596, 0.8192736237601085, 0.9698778517908518, 0.9917967031840592, 0.89568529901746, 0.48327855399077074, 0.5041394987673508, 0.010430472388290016, 0.13210067592386143, 0.0973373401544242, 0.7717460540815062, 0.08737607157109137, 0.06148686517965689, 0.3818657942736586, 0.02588920639143448, 0.2831631949063146, 0.016180753994646548, 0.14400871055235429], \"Term\": [\"abonner\", \"accident\", \"accident\", \"accuser\", \"accuser\", \"acc\\u00e8s_contenu\", \"acteur\", \"acteur\", \"actionnair\", \"activit\\u00e9\", \"activit\\u00e9\", \"activit\\u00e9\", \"activit\\u00e9\", \"activit\\u00e9\", \"afficher\", \"afficher\", \"affirmer\", \"affirmer\", \"affirmer\", \"affirmer\", \"affirmer\", \"affirmer\", \"affirmer\", \"agent\", \"agent\", \"agent\", \"aide\", \"aide\", \"aide\", \"alexander\", \"allemand\", \"allemand\", \"allemand\", \"aller\", \"aller\", \"aller\", \"aller\", \"aller\", \"aller\", \"aller\", \"aller\", \"alonso\", \"alternatif\", \"amateur\", \"amateur\", \"amuser\", \"am\\u00e9ricain\", \"am\\u00e9ricain\", \"am\\u00e9ricain\", \"am\\u00e9ricain\", \"ancien\", \"ancien\", \"ancien\", \"ancien\", \"ancien\", \"anderlecht\", \"anderlecht\", \"angleterre\", \"animal\", \"anniversaire\", \"annoncer\", \"annoncer\", \"annoncer\", \"annoncer\", \"annoncer\", \"annoncer\", \"annoncer\", \"annoncer\", \"ann\\u00e9e\", \"ann\\u00e9e\", \"ann\\u00e9e\", \"ann\\u00e9e\", \"ann\\u00e9e\", \"ann\\u00e9e\", \"ann\\u00e9e\", \"ann\\u00e9e\", \"antwerp\", \"ao\\u00fbt\", \"ao\\u00fbt\", \"ao\\u00fbt\", \"apercevoir\", \"appel\", \"appel\", \"appel\", \"appel\", \"appel\", \"appel\", \"application\", \"application\", \"apr\\u00e8smidi\", \"apr\\u00e8smidi\", \"apr\\u00e8smidi\", \"apr\\u00e8smidi\", \"apr\\u00e8smidi\", \"argent\", \"arr\\u00eat\\u00e9_royal\", \"article\", \"artificiel\", \"artiste\", \"assembl\\u00e9e_g\\u00e9n\\u00e9ral\", \"atil\", \"atil\", \"atil\", \"atil\", \"atil\", \"audience\", \"avenue\", \"avril\", \"avril\", \"avril\", \"avril\", \"avril\", \"a\\u00e9ronautique\", \"a\\u00e9roport\", \"baisse\", \"ball\", \"ball\", \"banqu\", \"bateau\", \"beau\", \"beaucoup\", \"beaucoup\", \"beaucoup\", \"beaucoup\", \"beaucoup\", \"beaucoup\", \"beaucoup\", \"belge\", \"belge\", \"belge\", \"belge\", \"belge\", \"belge\", \"belgiqu\", \"belgiqu\", \"belgiqu\", \"belgiqu\", \"belgiqu\", \"bernd_storck\", \"bien\", \"bien\", \"bien\", \"bien\", \"bien\", \"bien\", \"bien\", \"bien\", \"bien\", \"biodiversit\\u00e9\", \"blesser\", \"bon\", \"bon\", \"bon\", \"bon\", \"bon\", \"bouquet\", \"boursier\", \"bozar\", \"bo\\u00eete\", \"braban\\u00e7on\", \"britannique\", \"britannique\", \"britannique\", \"bruge\", \"bruge\", \"brugeois\", \"brugeois\", \"bruno\", \"bruxelle\", \"bruxelle\", \"bruxelle\", \"bruxelle\", \"bruxelle\", \"bruxellois\", \"bruxellois\", \"bruxellois\", \"bruxellois\", \"bruxellois\", \"business\", \"b\\u00e9b\\u00e9\", \"caf\\u00e9\", \"calendrier\", \"calendrier\", \"camion\", \"camp\", \"camp\", \"candidat\", \"candidat\", \"candidat\", \"candidat\", \"capteur\", \"carrefour\", \"carsten_spohr\", \"cellule\", \"chambouler\", \"chambre\", \"chambre\", \"chambre\", \"champion\", \"championnat\", \"change\", \"changer\", \"changer\", \"changer\", \"changer\", \"chanteur\", \"charle\", \"chaud\", \"chauffeur\", \"chef\", \"chef\", \"chef\", \"chef\", \"chef\", \"chemin\", \"chemin\", \"chien\", \"chiffr\", \"chiffre\", \"chiffre\", \"chin\", \"chin\", \"chinois\", \"chose\", \"chose\", \"chose\", \"chose\", \"chose\", \"chose\", \"chute\", \"cin\\u00e9art\", \"cin\\u00e9ma\", \"cin\\u00e9mer\", \"circonstance_exceptionnel\", \"citoyen\", \"citoyen\", \"classe\", \"classe\", \"classemer\", \"client\", \"client\", \"climat\", \"clinique\", \"clor\", \"club\", \"club\", \"club_bruge\", \"coach\", \"coalition\", \"coll\\u00e8ge\", \"command\", \"command\", \"commander\", \"commentair\", \"commission_licence\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"communal\", \"communal\", \"communal\", \"compagnie\", \"compagnie_a\\u00e9rien\", \"compl\\u00e9ter\", \"compte_acc\\u00e8\", \"compte_lire\", \"comp\\u00e9tition\", \"comp\\u00e9tition\", \"comp\\u00e9tition_sportif\", \"com\\u00e9die\", \"concerner\", \"concerner\", \"concerner\", \"concerner\", \"concert\", \"concert\", \"concert\", \"concour\", \"concours\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"confier\", \"confier\", \"confier\", \"confier\", \"confier\", \"confier\", \"confinemer\", \"confinemer\", \"confinemer\", \"confinemer\", \"confinemer\", \"conscience\", \"conseil_surveillance\", \"constructeur\", \"contact\", \"contact\", \"contact\", \"contact\", \"contagion\", \"contamination\", \"contaminer\", \"contrairement\", \"cookie\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"corps\", \"corps\", \"corps\", \"coulisse\", \"coupl\", \"couple\", \"covid\", \"covid\", \"covid\", \"covid\", \"co\\u00fbt\", \"co\\u00fbt\", \"criminel\", \"crise\", \"crise\", \"crise\", \"crise\", \"crise\", \"croate\", \"croate\", \"croissance\", \"cyclisme\", \"c\\u00e9r\\u00e9bral\", \"c\\u00e9r\\u00e9monie\", \"deadline\", \"demain\", \"demander\", \"demander\", \"demander\", \"demander\", \"demander\", \"demander\", \"dembler\", \"dernier\", \"dernier\", \"dernier\", \"dernier\", \"dernier\", \"dernier\", \"dernier\", \"dernier\", \"dernier\", \"devoir\", \"devoir\", \"devoir\", \"devoir\", \"devoir\", \"devoir\", \"devoir\", \"devoir\", \"devoir\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"dimanche\", \"dimanche\", \"dimanche\", \"dimanche\", \"dimanche\", \"dimanche\", \"dimanche\", \"dirigeant\", \"dirigeant\", \"discovery\", \"dispara\\u00eetre\", \"disponible\", \"disponible\", \"disponible\", \"disputer\", \"disputer\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"documentaire\", \"donald_trump\", \"donne\", \"donne\", \"donne\", \"donne\", \"donne\", \"donne\", \"donne\", \"donne\", \"donner\", \"donner\", \"donner\", \"donner\", \"donner\", \"donner\", \"donner\", \"donner\", \"donner\", \"dorer\", \"dossier\", \"dossier\", \"dossier\", \"dossier\", \"drame\", \"droit\", \"droit\", \"droit\", \"droit\", \"droit\", \"droit\", \"droite\", \"d\\u00e9bloquer\", \"d\\u00e9bloquer\", \"d\\u00e9but\", \"d\\u00e9but\", \"d\\u00e9but\", \"d\\u00e9but\", \"d\\u00e9but\", \"d\\u00e9but\", \"d\\u00e9but\", \"d\\u00e9but\", \"d\\u00e9cider\", \"d\\u00e9cider\", \"d\\u00e9cider\", \"d\\u00e9cider\", \"d\\u00e9cider\", \"d\\u00e9cider\", \"d\\u00e9cider\", \"d\\u00e9cision\", \"d\\u00e9cision\", \"d\\u00e9cision\", \"d\\u00e9cision\", \"d\\u00e9cision\", \"d\\u00e9cision\", \"d\\u00e9cision\", \"d\\u00e9clarer\", \"d\\u00e9clarer\", \"d\\u00e9clarer\", \"d\\u00e9clarer\", \"d\\u00e9clarer\", \"d\\u00e9clarer\", \"d\\u00e9clarer\", \"d\\u00e9clarer\", \"d\\u00e9c\\u00e8\", \"d\\u00e9c\\u00e8\", \"d\\u00e9c\\u00e8s\", \"d\\u00e9c\\u00e8s\", \"d\\u00e9c\\u00e9der\", \"d\\u00e9c\\u00e9der\", \"d\\u00e9fense\", \"d\\u00e9fense\", \"d\\u00e9fense\", \"d\\u00e9g\\u00e2t\", \"d\\u00e9part\", \"d\\u00e9part\", \"d\\u00e9part\", \"d\\u00e9pense\", \"d\\u00e9poser_pr\\u00e9avis\", \"d\\u00e9put\\u00e9\", \"d\\u00e9put\\u00e9\", \"d\\u00e9put\\u00e9\", \"d\\u00e9sinfecter\", \"d\\u00e9sinfecter\", \"d\\u00e9tecter\", \"ecolo\", \"edward\", \"effectif\", \"emmener\", \"emploi\", \"emploi\", \"emploi\", \"employer\", \"encontre\", \"enfant\", \"enfant\", \"enfant\", \"enfant\", \"enfant\", \"enregistrer\", \"enregistrer\", \"enregistrer\", \"enseignement\", \"enseignemer\", \"enseigner\", \"entit\\u00e9\", \"entra\\u00eenement\", \"entra\\u00eeneur\", \"entra\\u00eeneur\", \"entreprendre\", \"entreprise\", \"entreprise\", \"entreprise_familial\", \"envie\", \"environnemental\", \"eric\", \"espac\", \"espn\", \"espn\", \"espn\", \"espn\", \"esp\\u00e8ce\", \"etatsuni\", \"etatsuni\", \"eupen\", \"euro\", \"euro\", \"europ\\u00e9en\", \"europ\\u00e9en\", \"europ\\u00e9en\", \"europ\\u00e9en\", \"europ\\u00e9en\", \"examen\", \"examen\", \"excel_mouscron\", \"exister\", \"exister\", \"exister\", \"exister\", \"expliquer\", \"expliquer\", \"expliquer\", \"expliquer\", \"expliquer\", \"expliquer\", \"expliquer\", \"expliquer\", \"expliquer\", \"exposition\", \"facteur_demeur\", \"faire\", \"faire\", \"faire\", \"faire\", \"faire\", \"faire\", \"faire\", \"faire\", \"faire\", \"falloir\", \"falloir\", \"falloir\", \"falloir\", \"falloir\", \"falloir\", \"falloir\", \"falloir\", \"famille\", \"famille\", \"famille\", \"famille\", \"famille\", \"femme\", \"femme\", \"femme\", \"femme\", \"fen\\u00eatre\", \"ferrari\", \"festival\", \"fille\", \"fille\", \"fille\", \"film\", \"fils\", \"final\", \"final\", \"final\", \"final_coupe\", \"finaliser\", \"financer\", \"financier\", \"financier\", \"financier\", \"foisci\", \"football\", \"forc\\u00e9ment\", \"formation\", \"formation\", \"formation\", \"formation\", \"formation\", \"formation\", \"formul\", \"formul\", \"fournisseur\", \"frais\", \"fra\\u00eechement\", \"frer\", \"fr\\u00e9quenter\", \"f\\u00e9d\\u00e9ral\", \"f\\u00e9d\\u00e9ral\", \"f\\u00e9d\\u00e9ral\", \"f\\u00e9d\\u00e9ral\", \"f\\u00e9d\\u00e9ral\", \"f\\u00e9d\\u00e9ral\", \"f\\u00e9d\\u00e9ral\", \"f\\u00e9minin\", \"gardien\", \"gar\\u00e7on\", \"gar\\u00e7on\", \"genk\", \"gille\", \"gouvernement\", \"gouvernement\", \"gouvernement\", \"gouvernement\", \"gouvernement\", \"gouvernement\", \"gouvernement\", \"gouvernement\", \"gouvernement\", \"grand\", \"grand\", \"grand\", \"grand\", \"grand\", \"grand\", \"grand\", \"grand\", \"gratuit\", \"group\", \"group\", \"group\", \"groupe\", \"groupe\", \"groupe\", \"groupe\", \"groupe\", \"groupe\", \"groupe\", \"groupe\", \"gr\\u00e8v\", \"g\\u00e9n\\u00e9ration\", \"g\\u00e9n\\u00e9ration\", \"habitation\", \"hainaut\", \"heure\", \"heure\", \"heure\", \"heure\", \"heure\", \"heure\", \"histoire\", \"histoire\", \"histoire\", \"histoire\", \"homm\", \"hommage\", \"homme\", \"homme\", \"homme\", \"hong_kong\", \"horeca\", \"hospitalier\", \"hospitalisation\", \"hospitaliser\", \"huis_clore\", \"humidit\\u00e9\", \"hydroalcoolique\", \"h\\u00e9ritier\", \"h\\u00f4pital\", \"h\\u00f4pital\", \"imm\\u00e9diatement\", \"impact\", \"impact\", \"impact\", \"important\", \"important\", \"important\", \"important\", \"important\", \"important\", \"important\", \"incendie\", \"indiquer\", \"indiquer\", \"indiquer\", \"indiquer\", \"indiquer\", \"indiquer\", \"indiquer\", \"indiquer\", \"individu\", \"individu\", \"individu\", \"infecter\", \"infection\", \"infirmier\", \"infirmier\", \"instagram\", \"installer\", \"installer\", \"installer\", \"installer\", \"instruction\", \"instruction\", \"intense\", \"international\", \"international\", \"international\", \"international\", \"international\", \"intervenir\", \"intervenir\", \"intervenir\", \"intervenir\", \"intervenir\", \"intervenir\", \"intervenir\", \"investisseur\", \"investisseur\", \"invisible\", \"jamais\", \"jamais\", \"jamais\", \"jamais\", \"jamais\", \"jamais\", \"jamais\", \"jamais\", \"jamais\", \"jardin\", \"jazz\", \"jeu\", \"jeudi\", \"jeudi\", \"jeudi\", \"jeudi\", \"jeudi\", \"jeudi\", \"jeudi\", \"jeudi\", \"jeune\", \"jeune\", \"jeune\", \"jeune\", \"jeune\", \"jordan\", \"jouer\", \"jouer\", \"jouer\", \"joueur\", \"jour\", \"jour\", \"jour\", \"jour\", \"jour\", \"jour\", \"jour\", \"jour\", \"jour\", \"journaliste\", \"juillet\", \"juillet\", \"juillet\", \"juillet\", \"juillet\", \"julie\", \"jupiler_leagu\", \"kayak\", \"laatste_nieuw\", \"lactivit\\u00e9\", \"lafp\", \"lancer\", \"lancer\", \"lancer\", \"lancer\", \"lancer\", \"lancien\", \"lantwerp\", \"large\", \"large\", \"last_danc\", \"last_dance\", \"laszlo_b\\u00f6l\\u00f6ni\", \"laurent\", \"league\", \"lentrepri\", \"lhistoir\", \"lib\\u00e9rer\", \"licence\", \"licence\", \"ligue\", \"ligue_champion\", \"limiter\", \"limiter\", \"lindic\", \"litre\", \"littoral\", \"li\\u00e9geois\", \"loccasion\", \"lufthansa\", \"lufthansa\", \"lufthanser\", \"lundi\", \"lundi\", \"lundi\", \"lundi\", \"lundi\", \"lundi\", \"lundi\", \"l\\u00eele\", \"magasin\", \"magazine\", \"maillot\", \"maintien\", \"maison\", \"maison\", \"maison\", \"maison\", \"maison\", \"malade\", \"maladie\", \"manager\", \"manager\", \"manger\", \"marcher\", \"marcher\", \"march\\u00e9\", \"march\\u00e9\", \"mardi\", \"mardi\", \"mardi\", \"mardi\", \"mardi\", \"mardi\", \"mardi\", \"mardi\", \"mardi\", \"marketing\", \"marque\", \"marque\", \"mars\", \"mars\", \"mars\", \"mars\", \"mars\", \"martiner\", \"masqu\", \"masqu\", \"masqu\", \"masque\", \"masque\", \"masque_tissu\", \"match\", \"matin\", \"matin\", \"matin\", \"matin\", \"matin\", \"matin\", \"mensuel\", \"mercede\", \"mercredi\", \"mercredi\", \"mercredi\", \"mercredi\", \"mercredi\", \"mercredi\", \"mercredi\", \"mercredi\", \"mercredi\", \"mesure\", \"mesure\", \"mesure\", \"mesure\", \"mesure\", \"mesure\", \"mesure\", \"metteur_sc\\u00e8ne\", \"mettre\", \"mettre\", \"mettre\", \"mettre\", \"mettre\", \"mettre\", \"mettre\", \"mettre\", \"mexiqu\", \"michael_jordan\", \"midi\", \"midi\", \"migrer\", \"milliard\", \"million\", \"million\", \"million\", \"million\", \"million\", \"ministre\", \"ministre\", \"ministre\", \"ministre\", \"ministre\", \"ministre\", \"ministre_sophie\", \"mobiliser\", \"mobilit\\u00e9\", \"mobilit\\u00e9\", \"mois\", \"mois\", \"mois\", \"mois\", \"mois\", \"mois\", \"mois\", \"mois\", \"mois\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"monaco\", \"monaco\", \"mondial\", \"mondial\", \"mondial\", \"mondial\", \"mondial\", \"montant\", \"mort\", \"mort\", \"mort\", \"mort\", \"moto\", \"mouscron\", \"muser\", \"musical\", \"musicien\", \"musiqu\", \"musiqu\", \"m\\u00e8r\", \"m\\u00e9decin\", \"m\\u00e9decin\", \"m\\u00e9decine\", \"m\\u00e9dia\", \"m\\u00e9dia\", \"m\\u00e9dia\", \"m\\u00e9dicament\", \"m\\u00e9dicament\", \"m\\u00e9nage\", \"m\\u00e9nage\", \"m\\u00f6nchengladbach\", \"namur\", \"national\", \"national\", \"national\", \"national\", \"national\", \"national\", \"national\", \"nature\", \"nature\", \"net\", \"net\", \"netflix\", \"nick\", \"nombre\", \"nombre\", \"nombre\", \"nombre\", \"nouveau\", \"nouveau\", \"nouveau\", \"nouveau\", \"nouveau\", \"nouveau\", \"nouveau\", \"nouveau\", \"nouveau\", \"nuit\", \"nuit\", \"obligatoire\", \"obligatoire\", \"obligatoire\", \"occasion\", \"occasion\", \"olympique\", \"opportunit\\u00e9\", \"ordinaire\", \"ordinateur\", \"oublier\", \"oublier\", \"oublier\", \"oublier\", \"outreatlantiqu\", \"pairi_daiza\", \"pand\\u00e9mie\", \"pand\\u00e9mie\", \"pand\\u00e9mie\", \"pand\\u00e9mie\", \"pand\\u00e9mie\", \"pand\\u00e9mie\", \"pand\\u00e9mie\", \"papa\", \"parc\", \"pareil\", \"parer\", \"parfaitement\", \"parking\", \"parquet\", \"parquet\", \"parquet_namur\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"pascal_smet\", \"passer\", \"passer\", \"passer\", \"passer\", \"passer\", \"passer\", \"passer\", \"passer\", \"passer\", \"passer\", \"patient\", \"patron\", \"patron\", \"pay\", \"pay\", \"pay\", \"pay\", \"payer\", \"payer\", \"payer\", \"payer\", \"pays\", \"pays\", \"pays\", \"pays\", \"pays\", \"peau\", \"percevoir\", \"percuter\", \"permettre\", \"permettre\", \"permettre\", \"permettre\", \"permettre\", \"permettre\", \"personn\", \"personn\", \"personn\", \"personn\", \"personn\", \"personn\", \"personn\", \"personne\", \"personne\", \"personne\", \"personne\", \"personne\", \"personne\", \"personne\", \"personnel\", \"personnel\", \"personnel\", \"personnel\", \"personnel\", \"personnel\", \"personnel_soigner\", \"perte\", \"perte\", \"petit\", \"petit\", \"petit\", \"petit\", \"petit\", \"petit\", \"petit\", \"physiquement\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plage\", \"plainte\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"playoff\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"police\", \"police\", \"police\", \"policier\", \"policier\", \"politique\", \"politique\", \"politique\", \"politique\", \"politique\", \"pompier\", \"port\", \"poster\", \"pouvoir\", \"pouvoir\", \"pouvoir\", \"pouvoir\", \"pouvoir\", \"pouvoir\", \"pouvoir\", \"pouvoir\", \"pratique\", \"pratique\", \"prendre\", \"prendre\", \"prendre\", \"prendre\", \"prendre\", \"prendre\", \"prendre\", \"prendre\", \"prendre\", \"presse\", \"presse\", \"primaire\", \"prince\", \"princesse\", \"princip\", \"prochain\", \"prochain\", \"prochain\", \"prochain\", \"prochain\", \"prochain\", \"proc\\u00e8s\", \"produire\", \"produire\", \"produire\", \"produire\", \"professionnel\", \"professionnel\", \"professionnel\", \"professionnel\", \"professionnel\", \"proposition\", \"proposition\", \"proposition\", \"proposition\", \"propri\\u00e9taire\", \"propri\\u00e9taire\", \"propri\\u00e9taire\", \"protection\", \"protection\", \"protection\", \"protection\", \"prot\\u00e9ger\", \"prot\\u00e9ger\", \"prot\\u00e9ger\", \"provincial\", \"provincial\", \"pr\\u00e9sident\", \"pr\\u00e9sident\", \"pr\\u00e9sident\", \"pr\\u00e9sident\", \"pr\\u00e9sident\", \"pr\\u00e9sident\", \"pr\\u00e9venir\", \"pr\\u00e9venir\", \"pr\\u00e9venir\", \"pr\\u00e9venir\", \"pr\\u00e9venir\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"pur\", \"p\\u00e9kin\", \"qualifier\", \"qualifier\", \"quil\", \"quil\", \"quil\", \"quil\", \"quil\", \"quil\", \"quil\", \"quun\", \"raison\", \"raison\", \"raison\", \"raison\", \"raison\", \"raison\", \"raison\", \"raison\", \"raison\", \"raison\", \"rang\", \"rapport\", \"rapport\", \"rapport\", \"rapport\", \"rapport\", \"rapport\", \"rapport\", \"rassemblement\", \"recenser\", \"regarder\", \"reine\", \"rejeter\", \"relance\", \"relation\", \"relation\", \"relation\", \"remercier\", \"remont\", \"renault\", \"renault\", \"rentrer\", \"rentrer\", \"rentrer\", \"rentrer\", \"rentrer\", \"rentrer\", \"reprendre\", \"reprendre\", \"reprendre\", \"reprendre\", \"reprendre\", \"repr\\u00e9sentant_syndical\", \"repr\\u00e9senter\", \"repr\\u00e9senter\", \"repr\\u00e9senter\", \"repr\\u00e9senter\", \"repr\\u00e9senter\", \"respecter\", \"respecter\", \"respecter\", \"respecter\", \"responsable\", \"responsable\", \"responsable\", \"responsable\", \"responsable\", \"responsable\", \"retrouver\", \"retrouver\", \"retrouver\", \"retrouver\", \"retrouver\", \"retrouver\", \"risque\", \"risque\", \"risque\", \"risque\", \"risque\", \"risque\", \"risque\", \"riverain\", \"roberto_martiner\", \"rouvrir_port\", \"royal\", \"royal\", \"russie\", \"r\\u00e8glement\", \"r\\u00e9alisateur\", \"r\\u00e9duction\", \"r\\u00e9duction\", \"r\\u00e9ellement\", \"r\\u00e9fugier\", \"r\\u00e9gime\", \"r\\u00e9gion\", \"r\\u00e9gion\", \"r\\u00e9gion\", \"r\\u00e9gion\", \"r\\u00e9gion\", \"r\\u00e9servation\", \"r\\u00e9sident\", \"sainttrond\", \"saison\", \"salair\", \"salarier\", \"salarier\", \"salle\", \"salle\", \"samedi\", \"samedi\", \"samedi\", \"samedi\", \"samedi\", \"samedi\", \"samedi\", \"samedi\", \"sant\\u00e9\", \"sant\\u00e9\", \"sant\\u00e9\", \"sant\\u00e9\", \"sant\\u00e9\", \"sant\\u00e9\", \"sarscov\", \"sauver\", \"sauver\", \"savoir\", \"savoir\", \"savoir\", \"savoir\", \"savoir\", \"savoir\", \"savoir\", \"savoir\", \"sciensano\", \"scolaire\", \"sc\\u00e8ne\", \"sc\\u00e8ne\", \"sc\\u00e8ne\", \"secour\", \"secr\\u00e9taire\", \"secteur\", \"secteur\", \"secteur\", \"secteur\", \"semaine\", \"semaine\", \"semaine\", \"semaine\", \"semaine\", \"semaine\", \"semaine\", \"semaine\", \"semaine\", \"senior\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"sest\", \"sest\", \"sest\", \"sest\", \"sest\", \"situer\", \"situer\", \"situer\", \"situer\", \"situer\", \"social\", \"social\", \"social\", \"soci\\u00e9t\\u00e9\", \"soci\\u00e9t\\u00e9\", \"soci\\u00e9t\\u00e9\", \"soci\\u00e9t\\u00e9\", \"soin\", \"soin\", \"soin\", \"soin_intensif\", \"soir\", \"soir\", \"soir\", \"soir\", \"soir\", \"soir\", \"soirer\", \"soirer\", \"soirer\", \"soirer\", \"soixantedeux\", \"sommet\", \"sophie_wilm\\u00e8\", \"sortie\", \"sortie\", \"sortie\", \"sortir\", \"sortir\", \"sortir\", \"sortir\", \"sortir\", \"sortir\", \"sortir\", \"sortir\", \"soulever\", \"sourir\", \"spectacle\", \"sport\", \"sport\", \"sport\", \"sport\", \"sportif\", \"sportif\", \"sp\\u00e9cialiser\", \"stade\", \"stade\", \"stade\", \"stade\", \"stade\", \"startup\", \"stib\", \"strat\\u00e9gie\", \"strat\\u00e9gie\", \"strat\\u00e9gie\", \"strictement\", \"st\\u00e9phanie\", \"supporter\", \"supporter\", \"supporter\", \"sympt\\u00f4me\", \"syndical\", \"syndicat\", \"syndicat\", \"syndicat\", \"syst\\u00e8me\", \"syst\\u00e8me\", \"syst\\u00e8me\", \"syst\\u00e8me\", \"s\\u00e9curit\\u00e9\", \"s\\u00e9curit\\u00e9\", \"s\\u00e9curit\\u00e9\", \"s\\u00e9curit\\u00e9\", \"s\\u00e9curit\\u00e9\", \"s\\u00e9curit\\u00e9\", \"s\\u00e9lectionneur_diabl\", \"s\\u00e9ter\", \"s\\u00e9ter\", \"technologie\", \"technologie\", \"temps\", \"temps\", \"temps\", \"temps\", \"temps\", \"temps\", \"temps\", \"temp\\u00eate\", \"tenni\", \"tennis\", \"terrain\", \"terrain\", \"terrain\", \"terrain\", \"terrain\", \"terrain\", \"test\", \"test\", \"tester_positif\", \"texte\", \"texte\", \"th\\u00e9\\u00e2tre\", \"titre\", \"titre\", \"titre\", \"titre\", \"titre\", \"toilette\", \"toit\", \"tokyo\", \"total\", \"total\", \"total\", \"total\", \"total\", \"total\", \"tour_france\", \"touristique\", \"tournage\", \"tournoi\", \"trac\", \"traiter\", \"traiter\", \"transport\", \"transport\", \"travail\", \"travail\", \"travail\", \"travail\", \"travail\", \"travail\", \"travailleur\", \"travailleur\", \"travailleur\", \"tribunal\", \"tribunal\", \"tribunal_correctionnel\", \"trimestre\", \"tristesse\", \"trouver\", \"trouver\", \"trouver\", \"trouver\", \"trouver\", \"trouver\", \"trump\", \"t\\u00e9ler\", \"union\", \"uniquement\", \"uniquement\", \"unit\\u00e9\", \"utilisation\", \"utiliser\", \"utiliser\", \"utiliser\", \"utiliser\", \"vaccin\", \"vaccin\", \"vague\", \"vague\", \"vague\", \"vague\", \"vague\", \"veger\", \"veille\", \"veille\", \"veille\", \"vendeur\", \"vendeur\", \"vendr\", \"vendredi\", \"vendredi\", \"vendredi\", \"vendredi\", \"vendredi\", \"vendredi\", \"vendredi\", \"vendredi\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"vente\", \"victime\", \"victime\", \"vid\\u00e9o\", \"vid\\u00e9o\", \"vid\\u00e9o\", \"vid\\u00e9o\", \"vid\\u00e9o\", \"ville\", \"ville\", \"ville\", \"ville\", \"ville\", \"violence\", \"violence\", \"violence\", \"violence\", \"virologue\", \"virton\", \"viru\", \"viru\", \"virus\", \"virus\", \"visioconf\\u00e9rence\", \"visite\", \"visiteur\", \"visiteur\", \"vivre\", \"vivre\", \"vivre\", \"vivre\", \"vivre\", \"vivre\", \"voir\", \"voir\", \"voir\", \"voir\", \"voir\", \"voir\", \"voir\", \"voir\", \"voisin\", \"voisin\", \"voisin\", \"voisin\", \"voisin\", \"voitur\", \"voitur\", \"voiture\", \"voiture\", \"voiture\", \"voleur\", \"vote\", \"vote\", \"voulezvou_changer\", \"vouloir\", \"vouloir\", \"vouloir\", \"vouloir\", \"vouloir\", \"vouloir\", \"vouloir\", \"vouloir\", \"voyager\", \"vraiment\", \"vraiment\", \"vraiment\", \"vraiment\", \"v\\u00e9hicul\", \"v\\u00e9hicule\", \"v\\u00e9hicule\", \"v\\u00e9lo\", \"wilm\\u00e8\", \"zone\", \"zone\", \"zone\", \"\\u00e9chevin\", \"\\u00e9cole\", \"\\u00e9conomie\", \"\\u00e9conomie\", \"\\u00e9conomie\", \"\\u00e9conomique\", \"\\u00e9conomique\", \"\\u00e9crir\", \"\\u00e9crir\", \"\\u00e9crir\", \"\\u00e9crir\", \"\\u00e9crir\", \"\\u00e9crir\", \"\\u00e9dition\", \"\\u00e9dition\", \"\\u00e9lever\", \"\\u00e9lever\", \"\\u00e9lever\", \"\\u00e9pid\\u00e9mie\", \"\\u00e9pid\\u00e9mie\", \"\\u00e9pid\\u00e9mie\", \"\\u00e9pid\\u00e9mie\", \"\\u00e9pisode\", \"\\u00e9pisode\", \"\\u00e9pisode\", \"\\u00e9pisode\", \"\\u00e9quipe\", \"\\u00e9quipe\", \"\\u00e9quipe\", \"\\u00e9quipe\", \"\\u00e9quipe\", \"\\u00e9quipe\", \"\\u00e9tablissement\", \"\\u00e9tablissement\", \"\\u00e9tage\", \"\\u00e9tatsuni\", \"\\u00e9trange\", \"\\u00e9tude\", \"\\u00e9tude\", \"\\u00e9tude\", \"\\u00e9tudier\", \"\\u00e9tudier\", \"\\u00e9tudier\", \"\\u2019\", \"\\u2019\", \"\\u2019\", \"\\u2019\", \"\\u2019\", \"\\u2019\", \"\\u2019\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [12, 11, 8, 9, 2, 6, 3, 4, 7, 10, 5, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el36425421888143845833867562\", ldavis_el36425421888143845833867562_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el36425421888143845833867562\", ldavis_el36425421888143845833867562_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el36425421888143845833867562\", ldavis_el36425421888143845833867562_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "11     0.169119 -0.037054       1        1  17.322858\n",
       "10     0.164156 -0.004439       2        1  16.802366\n",
       "7      0.144580  0.141678       3        1  14.196478\n",
       "8      0.106853 -0.129569       4        1  10.413538\n",
       "1      0.066743 -0.086851       5        1  10.189698\n",
       "5      0.114302  0.065383       6        1  10.167856\n",
       "2      0.020563 -0.122038       7        1   6.924044\n",
       "3     -0.005561 -0.125028       8        1   6.334179\n",
       "6      0.063467  0.244646       9        1   5.876672\n",
       "9     -0.289715  0.019885      10        1   0.957951\n",
       "4     -0.278973  0.021159      11        1   0.608555\n",
       "0     -0.275535  0.012229      12        1   0.205804, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
       "742       saison   617.000000   617.000000  Default  30.0000  30.0000\n",
       "1403        club   587.000000   587.000000  Default  29.0000  29.0000\n",
       "39         covid   997.000000   997.000000  Default  28.0000  28.0000\n",
       "803        crise  1035.000000  1035.000000  Default  27.0000  27.0000\n",
       "314       police   522.000000   522.000000  Default  26.0000  26.0000\n",
       "...          ...          ...          ...      ...      ...      ...\n",
       "1018   diffusion     4.015369    49.603204  Topic12  -5.1458   3.6721\n",
       "156      épisode     4.230042    60.732625  Topic12  -5.0938   3.5217\n",
       "171          net     2.161843    17.446022  Topic12  -5.7650   4.0979\n",
       "4803        espn     2.599340    38.659798  Topic12  -5.5807   3.4865\n",
       "4060  génération     1.262718    44.778901  Topic12  -6.3027   2.6175\n",
       "\n",
       "[758 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "5654      1  0.996454   abonner\n",
       "899       4  0.072800  accident\n",
       "899       8  0.922128  accident\n",
       "1974      1  0.153953   accuser\n",
       "1974      5  0.837117   accuser\n",
       "...     ...       ...       ...\n",
       "114       3  0.381866         ’\n",
       "114       4  0.025889         ’\n",
       "114       6  0.283163         ’\n",
       "114       8  0.016181         ’\n",
       "114       9  0.144009         ’\n",
       "\n",
       "[1701 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[12, 11, 8, 9, 2, 6, 3, 4, 7, 10, 5, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m         final\u001b[39m.\u001b[39mappend(new)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m (final)\n\u001b[1;32m----> 7\u001b[0m data_words \u001b[39m=\u001b[39m gen_words(docs)\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(data_words)\n",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m, in \u001b[0;36mgen_words\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      2\u001b[0m final \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts : \n\u001b[1;32m----> 4\u001b[0m     new \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49msimple_preprocess(text,deacc\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      5\u001b[0m     final\u001b[39m.\u001b[39mappend(new)\n\u001b[0;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m (final)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\gensim\\utils.py:311\u001b[0m, in \u001b[0;36msimple_preprocess\u001b[1;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimple_preprocess\u001b[39m(doc, deacc\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, min_len\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, max_len\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m):\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \n\u001b[0;32m    291\u001b[0m \u001b[39m    Uses :func:`~gensim.utils.tokenize` internally.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m     tokens \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 311\u001b[0m         token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenize(doc, lower\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, deacc\u001b[39m=\u001b[39;49mdeacc, errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mignore\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    312\u001b[0m         \u001b[39mif\u001b[39;00m min_len \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(token) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m max_len \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    313\u001b[0m     ]\n\u001b[0;32m    314\u001b[0m     \u001b[39mreturn\u001b[39;00m tokens\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\gensim\\utils.py:262\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Iteratively yield tokens as unicode strings, optionally removing accent marks and lowercasing it.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \n\u001b[0;32m    230\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m \n\u001b[0;32m    260\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m lowercase \u001b[39m=\u001b[39m lowercase \u001b[39mor\u001b[39;00m to_lower \u001b[39mor\u001b[39;00m lower\n\u001b[1;32m--> 262\u001b[0m text \u001b[39m=\u001b[39m to_unicode(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    263\u001b[0m \u001b[39mif\u001b[39;00m lowercase:\n\u001b[0;32m    264\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\gensim\\utils.py:365\u001b[0m, in \u001b[0;36many2unicode\u001b[1;34m(text, encoding, errors)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m--> 365\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39;49m(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n",
      "\u001b[1;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, list found"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts : \n",
    "        new = gensim.utils.simple_preprocess(text,deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "data_words = gen_words(docs)\n",
    "print(data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dutch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from pymongo import *\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "#for many json texts\n",
    "import glob\n",
    "\n",
    "#visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nl_core_news_sm\n",
    "#nl_core_news_md\n",
    "#OR\n",
    "#nl_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"mongodb://bouman:80um4N!@ec2-15-188-255-64.eu-west-3.compute.amazonaws.com:27017/\"\n",
    "client = MongoClient(connection)\n",
    "db = client.get_database ('media_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all articles\n",
    "col = db[\"articles\"]\n",
    "#IT WORKS LEZGO\n",
    "nl_news = col.find({'meta.source.language': 'nl'},{\"_id\":0,\"title\": 1,\"text\":1,\"date\":1}).limit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Into the DataFrame\n",
    "df_nl = pd.DataFrame(data=nl_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     1\n",
       "text     3\n",
       "title    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking how many null values\n",
    "df_nl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting rows with null values\n",
    "df_nl = df_nl.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"dutch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Zonder al te technisch te worden, werkt het al...\n",
       "1       Het federale Overlegcomité heeft een handleidi...\n",
       "2       Door een gendefect hebben mucopatiënten last v...\n",
       "3       Ook dat nog Brit zoekt nieuwe hond en vindt… e...\n",
       "4       Na een lange vergadering hebben minister Weyts...\n",
       "                              ...                        \n",
       "2995    Topadviseur Boris Johnson moest thuis zitten, ...\n",
       "2996    Kroonprinses Elisabeth treedt toe tot ‘Class o...\n",
       "2997    NBA-woordvoerder bevestigt: gesprekken aan de ...\n",
       "2998    Terugblik op ramadan en voorbereiding Suikerfe...\n",
       "2999    Revaliderende Federer wil niet in lege stadion...\n",
       "Name: text, Length: 2996, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_nl[\"text\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nl.to_csv(\"nl_articles_3k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Didn't add the weird lemma, just a reminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m spacy_docs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(nlp\u001b[39m.\u001b[39;49mpipe(data))\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\language.py:1611\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[0;32m   1610\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[1;32m-> 1611\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[0;32m   1612\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:249\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1652\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1650\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1652\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mislice(items, \u001b[39mint\u001b[39m(batch_size)))\n\u001b[0;32m   1653\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1654\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\pipe.pyx:55\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1652\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1650\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1652\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mislice(items, \u001b[39mint\u001b[39m(batch_size)))\n\u001b[0;32m   1653\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1654\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:249\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1652\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1650\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1652\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mislice(items, \u001b[39mint\u001b[39m(batch_size)))\n\u001b[0;32m   1653\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1654\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1652\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1650\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1652\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mislice(items, \u001b[39mint\u001b[39m(batch_size)))\n\u001b[0;32m   1653\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1654\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1652\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1650\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1652\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mislice(items, \u001b[39mint\u001b[39m(batch_size)))\n\u001b[0;32m   1653\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1654\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\util.py:1705\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1696\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1697\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1703\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1704\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1705\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:75\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\spacy\\pipeline\\tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_dim(\u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc((\u001b[39m0\u001b[39m, width)) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[1;32m--> 126\u001b[0m tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(docs)\n\u001b[0;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\with_array.py:43\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\with_array.py:78\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     76\u001b[0m lengths \u001b[39m=\u001b[39m NUMPY_OPS\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[0;32m     77\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[1;32m---> 78\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[0;32m     81\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Desktop\\datatank_project\\capstone_project\\data_tank_env\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spacy_docs = list(nlp.pipe(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for doc in spacy_docs:\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if len(token.orth_) > 3 and not token.is_stop: # prétraitements 1 et 2\n",
    "            tokens.append( token.lemma_.lower() )  # prétraitements 3 et 4\n",
    "    docs.append( tokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "# def remove_stopwords(texts):\n",
    "#     return [[word for word in simple_preprocess(str(doc)) if word not in stopwords] for doc in texts]\n",
    "\n",
    "# def make_bigrams(texts):\n",
    "#     return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# def make_trigrams(texts):\n",
    "#     return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "# def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "#     texts_out = []\n",
    "#     for sent in texts:\n",
    "#         doc = nlp(\" \".join(sent)) \n",
    "#         texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "#     return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Stop Words\n",
    "# data_words_nostops = remove_stopwords(docs)\n",
    "\n",
    "# # Form Bigrams\n",
    "# data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# # Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# # python3 -m spacy download en\n",
    "# nlp = spacy.load('fr_core_news_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# # Do lemmatization keeping only noun, adj, vb, adv\n",
    "# data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# print(data_lemmatized[:3])\n",
    "# #Seems like it cuts weirdly, it has \"pèr\" and \"père\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "#replace docs by data_lemmatized\n",
    "id2word = corpora.Dictionary(docs)\n",
    "\n",
    "# Create Corpus\n",
    "#replace docs by data_lemmatized\n",
    "texts = docs\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=200,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "#replace docs by data_lemmatized\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=docs, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "#Best coherence NL = 0.42 (10 topics, 500 chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stops(text, stops):\n",
    "    words = text.split()\n",
    "    final = []\n",
    "    for word in words:\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "    final = \" \".join(final)\n",
    "    final = final.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    final = \"\".join([i for i in final if not i.isdigit()])\n",
    "    while \"  \"in final:\n",
    "        final = final.replace(\"  \",\" \")\n",
    "    return (final)\n",
    "    \n",
    "def clean_docs(docs):\n",
    "    stops = stopwords.words(\"french\")\n",
    "    final = []\n",
    "    for doc in docs:\n",
    "        clean_doc = remove_stops(doc,stops)\n",
    "        final.append(clean_doc)\n",
    "    return (final)\n",
    "\n",
    "cleaned_articles = clean_docs(articles)\n",
    "cleaned_articles[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "think_tank_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
